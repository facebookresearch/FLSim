{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python3",
      "language": "python",
      "name": "Python3",
      "metadata": {}
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "4dcf7f7d-d463-42f0-97d7-71e77cdb2b88",
    "last_kernel_id": "a2160017-dec8-4c85-ab1b-725ed083362a",
    "last_base_url": "",
    "last_msg_id": "dcee5f71-a85ac00b09c292d9be063e81_722",
    "captumWidgetMessage": {},
    "outputWidgetContext": {},
    "colab": {
      "name": "sent140_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "ef12966a-7e07-446b-b931-4235e269f994",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "3bK3FXzuwwWi"
      },
      "source": [
        "# FLSim Tutorial: Sentiment Classification with LEAF's Sent140\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "669ad0e3-282b-41be-aad0-2c111b3402be",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "-cud3a-RwwWl"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we will train a binary sentiment classifier on LEAF's Sent140 dataset with federated learning using FLSim. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "bcb5f56d-908e-4978-9e60-73c794d1de79",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "juLJefjwwwWl"
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "To get the most of this tutorial, you should be comfortable training machine learning models with **PyTorch** and familiar with the concept of **federated learning (FL)**. If you are unfamimiliar with either of them or could use a refresher, please take a look at the following resources before proceeding with the tutorial:\n",
        "\n",
        "- McMahan & Ramage (2017): [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html). A short blog post from Google AI introducing the main idea of FL in a beginner-friendly way.\n",
        "- McMahan et al. (2017): [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/pdf/1602.05629.pdf). This paper first proposes the approach of federated learning. The described algorithm is now known as federated averaging (or FedAvg for short).\n",
        "- PyTorch has [extensive tutorials](https://pytorch.org/tutorials/) on their website.\n",
        "- If you're new to **sentiment classification**, you can find Pang and Lee's survey on the topic [here](https://www.cs.cornell.edu/home/llee/omsa/omsa-published.pdf). \n",
        "\n",
        "Now that you're familiar with PyTorch and FL and have a sense of sentiment classification, let's move on!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6c37e934-b30b-4946-8acf-f308b487688f",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "BpAyiL32wwWm"
      },
      "source": [
        "### Objectives \n",
        "\n",
        "By the end of this tutorial, we will have learnt how to\n",
        "\n",
        "1. Build a data pipeline for federated learning with FLSim,\n",
        "2. Create an image classification model compatible with FL training,\n",
        "3. Set hyperparameters for FL training, \n",
        "4. Create a metrics reporter to collect metrics, and\n",
        "5. Launch an FL training flow using FLSim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "b2a57ec9-bb33-4df6-9608-0abe10445108",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "7ircLt3XwwWm"
      },
      "source": [
        "## Training a sentiment classifier with FLSim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puiDK1YnxjVF"
      },
      "source": [
        "### Prerequisite\n",
        "First, let's install flsim via pip with the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_RqvNSaxhGB",
        "outputId": "a362fb05-cc2e-430b-e74b-529609c4abab"
      },
      "source": [
        "!pip install --quiet flsim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 245 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 266 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 286 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 296 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 304 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 30.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 34.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 19.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.8 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5d2a8203-16cb-492a-a4cd-46b0a9456e21",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "LBS_CxQmwwWn"
      },
      "source": [
        "### 0. About the dataset\n",
        "\n",
        "For this tutorial, we're using [LEAF's](https://leaf.cmu.edu/) [Sentiment140 (Sent140) dataset](https://leaf.cmu.edu/build/html/tutorials/sent140-md.html), which consists of 1.6 million tweets by 660k users. Note that the mean number of samples per user is 2.42 and the standard deviation is 4.71.\n",
        "\n",
        "![Sent140 distribution of samples across users](https://leaf.cmu.edu/webpage/images/twitter_hist.png)\n",
        "\n",
        "Before the next step in this tutorial, you need to download the dataset and partition the data by users. \n",
        "We've included a script, `get_data.sh`, which will download and preproces the data for you. \n",
        "In particular, we sample 1% of the entire dataset in a non-IID manner and\n",
        "partition 90% of sampled users into train and 10% of sampled users into test (as opposed to individual samples).\n",
        "We require all users to have at least one sample.\n",
        "\n",
        "For more information on the various preprocessing options, see [here](https://github.com/TalwalkarLab/leaf/tree/master/data/sent140). You can find the LEAF paper [here](https://arxiv.org/pdf/1812.01097.pdf).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "59d5e611-102e-4d44-9478-cfd54f0ca81b",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "5ab54fa9-8358-41b9-91c5-ed36729a10b2",
        "executionStartTime": 1636676289207,
        "executionStopTime": 1636676290023,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf7oEQcXwwWn",
        "outputId": "be9a21ca-75c2-4ab5-da18-bb6ed27ffe99"
      },
      "source": [
        "import os\n",
        "# Clone the LEAF repo\n",
        "!git clone https://github.com/JohnlNguyen/leaf.git\n",
        "# cd into sent140 directory\n",
        "os.chdir(\"leaf/data/sent140\")\n",
        "# preprocess the data into user splits\n",
        "!sh ./preprocess.sh --sf 0.01 -s niid -t 'user' --tf 0.90 -k 1 --spltseed 1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'leaf'...\n",
            "remote: Enumerating objects: 763, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 763 (delta 12), reused 16 (delta 8), pack-reused 743\u001b[K\n",
            "Receiving objects: 100% (763/763), 6.78 MiB | 20.79 MiB/s, done.\n",
            "Resolving deltas: 100% (358/358), done.\n",
            "------------------------------\n",
            "retrieving raw data\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-11-23 22:06:04--  https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81363704 (78M) [application/zip]\n",
            "Saving to: ‘trainingandtestdata.zip’\n",
            "\n",
            "trainingandtestdata 100%[===================>]  77.59M  46.4MB/s    in 1.7s    \n",
            "\n",
            "2021-11-23 22:06:06 (46.4 MB/s) - ‘trainingandtestdata.zip’ saved [81363704/81363704]\n",
            "\n",
            "Archive:  trainingandtestdata.zip\n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n",
            "finished retrieving raw data\n",
            "------------------------------\n",
            "combining raw_data .csv files\n",
            "finished combining raw_data .csv files\n",
            "------------------------------\n",
            "converting data to .json format\n",
            "finished converting data to .json format\n",
            "------------------------------\n",
            "sampling data\n",
            "Using seed 1637705226\n",
            "/content/leaf/data/sent140/leaf/data/sent140/meta\n",
            "- random seed written out to /content/leaf/data/sent140/leaf/data/sent140/meta/sampling_seed.txt\n",
            "writing all_data_niid_01.json\n",
            "------------------------------\n",
            "removing users with less than 1 samples\n",
            "writing all_data_niid_01_keep_1.json\n",
            "------------------------------\n",
            "generating training and test sets\n",
            "- random seed written out to /content/leaf/data/sent140/leaf/data/sent140/meta/split_seed.txt\n",
            "splitting data by user\n",
            "writing all_data_0_01_keep_1_train_9.json\n",
            "writing all_data_0_01_keep_1_test_9.json\n",
            "------------------------------\n",
            "calculating JSON file checksums\n",
            "checksums written to meta/dir-checksum.md5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6d9d0efd-fcaa-4017-beb6-c9da31b4094e",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "1TTM_kfewwWp"
      },
      "source": [
        "We can find the preprocessed training and test data here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d3836318-4ccb-4fbd-bd33-af77d6b72d17",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "92a8c570-a267-45c6-b2d1-950fde49c110",
        "executionStartTime": 1636676290126,
        "executionStopTime": 1636676290307,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGAfuehiwwWq",
        "outputId": "cf8e7202-1712-4c60-b04b-38ad78626a27"
      },
      "source": [
        "!ls data/train; ls data/test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_data_0_01_keep_1_train_9.json\n",
            "all_data_0_01_keep_1_test_9.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "72744006-8d85-4ab0-b377-2572ae84bd25",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "x-kO6xicwwWr"
      },
      "source": [
        "Note: if you use different preprocessing options, you will need to change these!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a27a936f-9c09-4884-a792-0cd118687116",
        "showInput": true,
        "requestMsgId": "4fb9c5e3-9a89-4081-b589-f9e1286bce9e",
        "executionStartTime": 1636676290310,
        "executionStopTime": 1636676290315,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "h9zy21dbwwWr"
      },
      "source": [
        "TRAIN_DATA = \"data/train/all_data_0_01_keep_1_train_9.json\"\n",
        "TEST_DATA = \"data/test/all_data_0_01_keep_1_test_9.json\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "20691777-83ab-4406-84c5-950fa4b2224f",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "c4CBtqqQwwWr"
      },
      "source": [
        "We can now get a rough idea of the structure of the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8cc146cc-61db-445c-9c8c-8528226d3b80",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "26f25906-c0a5-43fe-a025-e4b39a598570",
        "executionStartTime": 1636676290335,
        "executionStopTime": 1636676290360,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOF_pdovwwWs",
        "outputId": "8d4a6598-bb55-4bcf-dea2-cc9f5bc43911"
      },
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open(TRAIN_DATA, \"r\") as f:\n",
        "    training_data = json.load(f)\n",
        "\n",
        "    # get overall structure of the data\n",
        "    for key, val in training_data.items():\n",
        "        print(key, type(val), len(val))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "users <class 'list'> 5765\n",
            "num_samples <class 'list'> 5765\n",
            "user_data <class 'dict'> 5765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "2b202d71-bac7-43d3-943b-f4b8a5f391a6",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "DzBsgOUBwwWs"
      },
      "source": [
        "We can compute the minimum, maximum, and mean number of samples per user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e774e6c4-91b0-4da0-9632-17f891980d44",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "06ec3dbb-2ed1-4551-9861-f8f580401549",
        "executionStartTime": 1636676290379,
        "executionStopTime": 1636676290383,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syKpJRyMwwWs",
        "outputId": "973ef9b4-27a3-459e-c0ea-230e455dd19b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(f\"Min # samples per user: {min(training_data['num_samples'])}\")\n",
        "print(f\"Max # samples per user: {max(training_data['num_samples'])}\")\n",
        "print(f\"Mean # samples per user: {np.mean(training_data['num_samples']):.2f}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min # samples per user: 1\n",
            "Max # samples per user: 211\n",
            "Mean # samples per user: 2.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "d596da87-913c-4079-8d81-65914d0665db",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "Fe8IMBouwwWt"
      },
      "source": [
        "Let us also look at the data for an example user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4d8c298b-b1c4-48e9-bf09-0217abe97393",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "a706da0d-e298-4e63-b2c0-c5ac97a43f64",
        "executionStartTime": 1636676290400,
        "executionStopTime": 1636676290432,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnkgnhX0wwWt",
        "outputId": "6144c97a-ad73-4c64-973f-f35a998dd392"
      },
      "source": [
        "EXAMPLE_USER = training_data[\"users\"][0]\n",
        "training_data[\"user_data\"][EXAMPLE_USER]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': [['2005866144',\n",
              "   'Tue Jun 02 10:18:00 PDT 2009',\n",
              "   'NO_QUERY',\n",
              "   'eriinL',\n",
              "   'has to go to knightdale next year. ',\n",
              "   'training'],\n",
              "  ['2015140062',\n",
              "   'Wed Jun 03 03:49:28 PDT 2009',\n",
              "   'NO_QUERY',\n",
              "   'eriinL',\n",
              "   'Theatre exam ',\n",
              "   'training']],\n",
              " 'y': [0, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "7152ba71-9205-408c-a369-00308e75314a",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "KDu2plpYwwWt"
      },
      "source": [
        "### 1. Data pipeline\n",
        "\n",
        "Now, let us define how to build the data pipeline for federated learning:\n",
        "\n",
        "1. To load the training and test data, we define a new dataset class, `Sent140Dataset`, which converts each user's tweets (features) into a `torch.Tensor`, discarding tweet metadata such as time, and stores each tweet's sentiment (label) as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "77651659-ce0a-48ef-947b-ca898bb3793f",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "791e752f-82c1-444d-9ced-3716af1460c9",
        "executionStartTime": 1636676290438,
        "executionStopTime": 1636676291421,
        "id": "FXSXs8pTwwWt"
      },
      "source": [
        "import itertools\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# 1. Sent140Dataset will store the tweets and corresponding sentiment for each user.\n",
        "\n",
        "\n",
        "class Sent140Dataset(Dataset):\n",
        "    def __init__(self, data_root, max_seq_len):\n",
        "        self.data_root = data_root\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.all_letters = {c: i for i, c in enumerate(string.printable)}\n",
        "        self.num_letters = len(self.all_letters)\n",
        "        self.UNK = self.num_letters\n",
        "\n",
        "        with open(data_root, \"r+\") as f:\n",
        "            self.dataset = json.load(f)\n",
        "\n",
        "        self.data = {}\n",
        "        self.targets = {}\n",
        "\n",
        "        self.num_classes = 2  # binary sentiment classification\n",
        "\n",
        "        # Populate self.data and self.targets\n",
        "        for user_id, user_data in self.dataset[\"user_data\"].items():\n",
        "            self.data[user_id] = self.process_x(list(user_data[\"x\"]))\n",
        "            self.targets[user_id] = self.process_y(list(user_data[\"y\"]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for user_id in self.data.keys():\n",
        "            yield self.__getitem__(user_id)\n",
        "\n",
        "    def __getitem__(self, user_id: str):\n",
        "        if user_id not in self.data or user_id not in self.targets:\n",
        "            raise IndexError(f\"User {user_id} is not in dataset\")\n",
        "\n",
        "        return self.data[user_id], self.targets[user_id]\n",
        "\n",
        "    def unicodeToAscii(self, s):\n",
        "        return \"\".join(\n",
        "            c\n",
        "            for c in unicodedata.normalize(\"NFD\", s)\n",
        "            if unicodedata.category(c) != \"Mn\" and c in self.all_letters\n",
        "        )\n",
        "\n",
        "    def line_to_indices(self, line: str, max_seq_len: int):\n",
        "        line_list = self.split_line(line)  # split phrase in words\n",
        "        line_list = line_list\n",
        "        chars = self.flatten_list([list(word) for word in line_list])\n",
        "        indices = [\n",
        "            self.all_letters.get(letter, self.UNK)\n",
        "            for i, letter in enumerate(chars)\n",
        "            if i < max_seq_len\n",
        "        ]\n",
        "        # Add padding\n",
        "        indices = indices + [self.UNK] * (max_seq_len - len(indices))\n",
        "        return indices\n",
        "\n",
        "    def process_x(self, raw_x_batch):\n",
        "        x_batch = [e[4] for e in raw_x_batch]  # e[4] contains the actual tweet\n",
        "        x_batch = [self.line_to_indices(e, self.max_seq_len) for e in x_batch]\n",
        "        x_batch = torch.LongTensor(x_batch)\n",
        "        return x_batch\n",
        "\n",
        "    def process_y(self, raw_y_batch):\n",
        "        y_batch = [int(e) for e in raw_y_batch]\n",
        "        return y_batch\n",
        "\n",
        "    def split_line(self, line):\n",
        "        \"\"\"\n",
        "        Split given line/phrase into list of words\n",
        "\n",
        "        Args:\n",
        "            line: string representing phrase to be split\n",
        "\n",
        "        Return:\n",
        "            list of strings, with each string representing a word\n",
        "        \"\"\"\n",
        "        return re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "\n",
        "    def flatten_list(self, nested_list):\n",
        "        return list(itertools.chain.from_iterable(nested_list))\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "f76ded33-fb91-4978-96ce-da9a65d8c7dc",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "hbiVkmP-wwWu"
      },
      "source": [
        "2. We can now load the train and test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4f2e40f3-8e8d-4590-803a-6210cd4455c4",
        "showInput": true,
        "requestMsgId": "5b6ad058-f5e0-4616-a05c-b9c1ec19fb01",
        "executionStartTime": 1636676291516,
        "executionStopTime": 1636676292257,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "0vYKdrt3wwWu"
      },
      "source": [
        "MAX_SEQ_LEN = 25\n",
        "\n",
        "\n",
        "# 2. Load the train and test datasets.\n",
        "train_dataset = Sent140Dataset(\n",
        "    data_root=TRAIN_DATA,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        ")\n",
        "test_dataset = Sent140Dataset(\n",
        "    data_root=TEST_DATA,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        ")\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "63946b49-8f29-473a-a694-4aa68e982593",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "l6rAlDeEwwWu"
      },
      "source": [
        "Recall our `EXAMPLE_USER` from earlier? Their data now looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8c2b0f96-2836-42b5-9d3b-cc468fb20a7a",
        "showInput": true,
        "requestMsgId": "0ecb6209-5c9c-45a3-adb7-1abb17865411",
        "executionStartTime": 1636676292269,
        "executionStopTime": 1636676292273,
        "code_folding": [],
        "hidden_ranges": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KnHlbMxwwWu",
        "outputId": "64b6cf2f-65a5-4131-f921-133cafaaff51"
      },
      "source": [
        "train_dataset[EXAMPLE_USER]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 17,  10,  28,  29,  24,  16,  24,  29,  24,  20,  23,  18,  16,  17,\n",
              "           29,  13,  10,  21,  14,  23,  14,  33,  29,  34,  14],\n",
              "         [ 55,  17,  14,  10,  29,  27,  14,  14,  33,  10,  22, 100, 100, 100,\n",
              "          100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]]), [0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "dd5a34ad-bf41-4b6b-82db-8dc528131310",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "wiZCKU_-wwWv"
      },
      "source": [
        "To complete our data pipeline, we only need to\n",
        "\n",
        "3. Create a data loader, which will batchify training, eval, and test data. There is no need to create a sharder since the data is already sharded. For each dataset, the data loader splits each client's data into batches of size `batch_size`. We choose not to drop the last batch.\n",
        "\n",
        "4. Lastly, wrap the data loader with a data provider and return it. \n",
        "The data provider creates clients from the groupings in the data loader and adds metadata (e.g. number of examples, number of batches per client). \n",
        "Our data is now formatted such that the trainer will accept it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "09659734-9020-4f0e-a01f-4491a8f700c8",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "52557db1-39c7-4695-b7c6-f3ac73ad8a0c",
        "executionStartTime": 1636676292361,
        "executionStopTime": 1636676295007,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSuOmXIpwwWv",
        "outputId": "8b6b0fb9-f305-4ce8-aec8-1717430c046e"
      },
      "source": [
        "import random\n",
        "from typing import Any, Dict, Generator, Iterable, Iterator, List, Tuple\n",
        "\n",
        "from flsim.data.data_provider import IFLDataProvider, IFLUserData\n",
        "from flsim.interfaces.data_loader import IFLDataLoader\n",
        "from flsim.utils.data.data_utils import batchify\n",
        "from tqdm import tqdm\n",
        "\n",
        "class LEAFDataLoader(IFLDataLoader):\n",
        "    SEED = 2137\n",
        "    random.seed(SEED)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_dataset: Dataset,\n",
        "        eval_dataset: Dataset,\n",
        "        test_dataset: Dataset,\n",
        "        batch_size: int,\n",
        "        drop_last: bool = False,\n",
        "    ):\n",
        "        self.train_dataset = train_dataset\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = drop_last\n",
        "\n",
        "    def fl_train_set(self, **kwargs) -> Iterable[Dict[str, Generator]]:\n",
        "        yield from self._batchify(self.train_dataset, self.drop_last)\n",
        "\n",
        "    def fl_eval_set(self, **kwargs) -> Iterable[Dict[str, Generator]]:\n",
        "        yield from self._batchify(self.eval_dataset, drop_last=False)\n",
        "\n",
        "    def fl_test_set(self, **kwargs) -> Iterable[Dict[str, Generator]]:\n",
        "        yield from self._batchify(self.test_dataset, drop_last=False)\n",
        "\n",
        "    def _batchify(\n",
        "        self, dataset: Dataset, drop_last=False\n",
        "    ) -> Generator[Dict[str, Generator], None, None]:\n",
        "        for one_user_inputs, one_user_labels in dataset:\n",
        "            data = list(zip(one_user_inputs, one_user_labels))\n",
        "            random.shuffle(data)\n",
        "            one_user_inputs, one_user_labels = zip(*data)\n",
        "            batch = {\n",
        "                \"features\": batchify(one_user_inputs, self.batch_size, drop_last),\n",
        "                \"labels\": batchify(one_user_labels, self.batch_size, drop_last),\n",
        "            }\n",
        "            yield batch\n",
        "\n",
        "\n",
        "class LEAFUserData(IFLUserData):\n",
        "    def __init__(self, user_data: Dict[str, Generator]):\n",
        "        self._user_batches = []\n",
        "        self._num_batches = 0\n",
        "        self._num_examples = 0\n",
        "        for features, labels in zip(user_data[\"features\"], user_data[\"labels\"]):\n",
        "            self._num_batches += 1\n",
        "            self._num_examples += LEAFUserData.get_num_examples(labels)\n",
        "            self._user_batches.append(LEAFUserData.fl_training_batch(features, labels))\n",
        "\n",
        "    def __iter__(self) -> Iterator[Dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Iterator to return a user batch data\n",
        "        \"\"\"\n",
        "        for batch in self._user_batches:\n",
        "            yield batch\n",
        "\n",
        "    def num_examples(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the number of examples\n",
        "        \"\"\"\n",
        "        return self._num_examples\n",
        "\n",
        "    def num_batches(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the number of batches\n",
        "        \"\"\"\n",
        "        return self._num_batches\n",
        "\n",
        "    @staticmethod\n",
        "    def get_num_examples(batch: List) -> int:\n",
        "        return len(batch)\n",
        "\n",
        "    @staticmethod\n",
        "    def fl_training_batch(\n",
        "        features: List[torch.Tensor], labels: List[float]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        return {\"features\": torch.stack(features), \"labels\": torch.Tensor(labels)}\n",
        "\n",
        "\n",
        "class LEAFDataProvider(IFLDataProvider):\n",
        "    def __init__(self, data_loader):\n",
        "        self.data_loader = data_loader\n",
        "        self.train_users = self._create_fl_users(data_loader.fl_train_set())\n",
        "        self.eval_users = self._create_fl_users(data_loader.fl_eval_set())\n",
        "        self.test_users = self._create_fl_users(data_loader.fl_test_set())\n",
        "\n",
        "    def user_ids(self) -> List[int]:\n",
        "        return list(self.train_users.keys())\n",
        "\n",
        "    def num_users(self) -> int:\n",
        "        return len(self.train_users)\n",
        "\n",
        "    def get_user_data(self, user_index: int) -> IFLUserData:\n",
        "        if user_index in self.train_users:\n",
        "            return self.train_users[user_index]\n",
        "        else:\n",
        "            raise IndexError(\n",
        "                f\"Index {user_index} is out of bound for list with len {self.num_users()}\"\n",
        "            )\n",
        "\n",
        "    def train_data(self) -> Iterable[IFLUserData]:\n",
        "        for user_data in self.train_users.values():\n",
        "            yield user_data\n",
        "\n",
        "    def eval_data(self) -> Iterable[Dict[str, torch.Tensor]]:\n",
        "        for user_data in self.eval_users.values():\n",
        "            for batch in user_data:\n",
        "                yield batch\n",
        "\n",
        "    def test_data(self) -> Iterable[Dict[str, torch.Tensor]]:\n",
        "        for user_data in self.test_users.values():\n",
        "            for batch in user_data:\n",
        "                yield batch\n",
        "\n",
        "    def _create_fl_users(self, iterator: Iterator) -> Dict[int, IFLUserData]:\n",
        "        return {\n",
        "            user_index: LEAFUserData(user_data)\n",
        "            for user_index, user_data in tqdm(\n",
        "                enumerate(iterator), desc=\"Creating FL User\", unit=\"user\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "# 3. Batchify training, eval, and test data. Note that train_dataset is already sharded.\n",
        "dataloader = LEAFDataLoader(\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "# 4. Wrap the data loader with a data provider.\n",
        "data_provider = LEAFDataProvider(dataloader)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating FL User: 5765user [00:00, 13622.88user/s]\n",
            "Creating FL User: 641user [00:00, 15256.34user/s]\n",
            "Creating FL User: 641user [00:00, 14588.76user/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "85636a6d-4c4b-49ea-9e82-34b3a9ddcbb3",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "GX0OAHeDwwWv"
      },
      "source": [
        "### 2. Create the model\n",
        "\n",
        "Now, let's see how we can create a model that is compatible with FL-training.\n",
        "\n",
        "1. First, we define a standard, non-FL sentiment classification pytorch `nn.Module`; in this tutorial we use a simple char-LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "257233d5-1f9f-47e3-8b1b-63ea4060e0c2",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "e74219b0-4bc2-4520-ba01-e0650091ca80",
        "executionStartTime": 1636676295011,
        "executionStopTime": 1636676295015,
        "id": "6AIQwthCwwWv"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "# 1. Define our model, a simple char-LSTM.\n",
        "\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        n_hidden,\n",
        "        num_embeddings,\n",
        "        embedding_dim,\n",
        "        max_seq_len,\n",
        "        dropout_rate,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.n_hidden = n_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_embeddings = num_embeddings\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.num_embeddings, embedding_dim=embedding_dim\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=self.n_hidden,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout_rate,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.n_hidden, self.num_classes)\n",
        "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_lens = torch.sum(x != (self.num_embeddings - 1), 1) - 1\n",
        "        x = self.embedding(x)  # [B, S] -> [B, S, E]\n",
        "        out, _ = self.lstm(x)  # [B, S, E] -> [B, S, H]\n",
        "        out = out[torch.arange(out.size(0)), seq_lens]\n",
        "        out = self.fc(self.dropout(out))  # [B, S, H] -> # [B, S, C]\n",
        "        return out\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "e78f06ab-88a9-44e9-b8f8-5c8ced763143",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "atIL7DqowwWw"
      },
      "source": [
        "We initialize our model wich such parameters that it is compatible with our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "24f03560-4a92-4f0c-8ad6-98568144a441",
        "showInput": true,
        "requestMsgId": "ca0a4f69-053e-4149-87c8-b9c037ad9027",
        "executionStartTime": 1636676295021,
        "executionStopTime": 1636676295027,
        "code_folding": [],
        "hidden_ranges": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKgeu4pPwwWw",
        "outputId": "db90c6f7-16e1-4aa9-df19-6f69a086883c"
      },
      "source": [
        "model = CharLSTM(\n",
        "    num_classes=train_dataset.num_classes,\n",
        "    n_hidden=100,\n",
        "    num_embeddings=train_dataset.num_letters + 1,\n",
        "    embedding_dim=100,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    dropout_rate=0.1,\n",
        ")\n",
        "\n",
        "model\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharLSTM(\n",
              "  (embedding): Embedding(101, 100)\n",
              "  (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.1)\n",
              "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "37dd6b2d-f4e1-49bb-b13f-7e6e74f9339e",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "4AiZtsUgwwWw"
      },
      "source": [
        "After we have our standard PyTorch model, we can\n",
        "\n",
        "2. Create a `torch.device` and choose where the model will be allocated (CUDA or CPU). \n",
        "\n",
        "3. Wrap the pytorch module with the FLSim `FLModel`. `FLModel` is accepted by the trainer and handles moving our model, data, and predictions to GPU if desired. It also collects and returns metrics for each batch it predicts on. You can find its implementation [here](https://github.com/facebookresearch/FLSim/blob/main/baselines/models/cv_model.py)\n",
        "\n",
        "4. Move the model to GPU and enable CUDA if desired.\n",
        "\n",
        "The model now supports FL training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f5a19f8d-34ca-4342-98e3-c68ea9ae7e0d",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "2f20621b-5f97-4396-adb5-e04ca2cebd92",
        "executionStartTime": 1636676295032,
        "executionStopTime": 1636676295038,
        "id": "QhGGhfkhwwWw"
      },
      "source": [
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from flsim.interfaces.model import IFLModel\n",
        "from flsim.utils.simple_batch_metrics import FLBatchMetrics\n",
        "\n",
        "class FLModel(IFLModel):\n",
        "    def __init__(self, model: nn.Module, device: Optional[str] = None):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "\n",
        "    def fl_forward(self, batch) -> FLBatchMetrics:\n",
        "        features = batch[\"features\"]  # [B, C, 28, 28]\n",
        "        batch_label = batch[\"labels\"]\n",
        "        stacked_label = batch_label.view(-1).long().clone().detach()\n",
        "        if self.device is not None:\n",
        "            features = features.to(self.device)\n",
        "\n",
        "        output = self.model(features)\n",
        "\n",
        "        if self.device is not None:\n",
        "            output, batch_label, stacked_label = (\n",
        "                output.to(self.device),\n",
        "                batch_label.to(self.device),\n",
        "                stacked_label.to(self.device),\n",
        "            )\n",
        "\n",
        "        loss = F.cross_entropy(output, stacked_label)\n",
        "        num_examples = self.get_num_examples(batch)\n",
        "        output = output.detach().cpu()\n",
        "        stacked_label = stacked_label.detach().cpu()\n",
        "        del features\n",
        "        return FLBatchMetrics(\n",
        "            loss=loss,\n",
        "            num_examples=num_examples,\n",
        "            predictions=output,\n",
        "            targets=stacked_label,\n",
        "            model_inputs=[],\n",
        "        )\n",
        "\n",
        "    def fl_create_training_batch(self, **kwargs):\n",
        "        features = kwargs.get(\"features\", None)\n",
        "        labels = kwargs.get(\"labels\", None)\n",
        "        return LEAFUserData.fl_training_batch(features, labels)\n",
        "\n",
        "    def fl_get_module(self) -> nn.Module:\n",
        "        return self.model\n",
        "\n",
        "    def fl_cuda(self) -> None:\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def get_eval_metrics(self, batch) -> FLBatchMetrics:\n",
        "        with torch.no_grad():\n",
        "            return self.fl_forward(batch)\n",
        "\n",
        "    def get_num_examples(self, batch) -> int:\n",
        "        return LEAFUserData.get_num_examples(batch[\"labels\"])\n",
        "\n",
        "\n",
        "USE_CUDA = True\n",
        "\n",
        "# 2. Choose where the model will be allocated.\n",
        "cuda_enabled = torch.cuda.is_available() and USE_CUDA\n",
        "device = torch.device(f\"cuda:{0}\" if cuda_enabled else \"cpu\")\n",
        "\n",
        "# 3. Wrap the model in FLModel.\n",
        "global_model = FLModel(model, device)\n",
        "\n",
        "# 4. Enable CUDA if desired.\n",
        "if cuda_enabled:\n",
        "    global_model.fl_cuda()\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCyGjCr73xfv"
      },
      "source": [
        "### 3. Metrics Reporting\n",
        "\n",
        "After we created our data pipeline and FL model, we then define our metrics reporter. The metrics reporter allows us to collect metrics and log them onto tensorboard. \n",
        "\n",
        "There are three functions that we care about: \n",
        "\n",
        "1. `compare_metrics`: This function compares the current eval metric that is returned from `create_eval_metrics` which we will define below. \n",
        "\n",
        "2. `compute_scores`: This function calculates the metrics that we care both. In this case, we would like to report the top1 accuracy. \n",
        "\n",
        "3. `create_eval_metrics`: This function creates the eval metrics dictionary that can be used by `compare_metrics` above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2BAOR3130GI"
      },
      "source": [
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import torch\n",
        "from flsim.common.timeline import Timeline\n",
        "from flsim.interfaces.metrics_reporter import Channel, TrainingStage\n",
        "from flsim.metrics_reporter.tensorboard_metrics_reporter import FLMetricsReporter\n",
        "\n",
        "class MetricsReporter(FLMetricsReporter):\n",
        "    ACCURACY = \"Accuracy\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: List[Channel],\n",
        "        target_eval: float = 0.0,\n",
        "        window_size: int = 5,\n",
        "        log_dir: Optional[str] = None,\n",
        "    ):\n",
        "        super().__init__(channels, log_dir)\n",
        "        self.set_summary_writer(log_dir=log_dir)\n",
        "\n",
        "    def compare_metrics(self, eval_metrics, best_metrics):\n",
        "        print(f\"Current eval accuracy: {eval_metrics}%, Best so far: {best_metrics}%\")\n",
        "        if best_metrics is None:\n",
        "            return True\n",
        "\n",
        "        current_accuracy = eval_metrics.get(self.ACCURACY, float(\"-inf\"))\n",
        "        best_accuracy = best_metrics.get(self.ACCURACY, float(\"-inf\"))\n",
        "        return current_accuracy > best_accuracy\n",
        "\n",
        "    def compute_scores(self) -> Dict[str, Any]:\n",
        "        # compute accuracy\n",
        "        correct = torch.Tensor([0])\n",
        "        for i in range(len(self.predictions_list)):\n",
        "            all_preds = self.predictions_list[i]\n",
        "            pred = all_preds.data.max(1, keepdim=True)[1]\n",
        "\n",
        "            assert pred.device == self.targets_list[i].device, (\n",
        "                f\"Pred and targets moved to different devices: \"\n",
        "                f\"pred >> {pred.device} vs. targets >> {self.targets_list[i].device}\"\n",
        "            )\n",
        "            if i == 0:\n",
        "                correct = correct.to(pred.device)\n",
        "\n",
        "            correct += pred.eq(self.targets_list[i].data.view_as(pred)).sum()\n",
        "\n",
        "        # total number of data\n",
        "        total = sum(len(batch_targets) for batch_targets in self.targets_list)\n",
        "\n",
        "        accuracy = 100.0 * correct.item() / total\n",
        "        return {self.ACCURACY: accuracy}\n",
        "\n",
        "    def create_eval_metrics(\n",
        "        self, scores: Dict[str, Any], total_loss: float, **kwargs\n",
        "    ) -> Any:\n",
        "        timeline: Timeline = kwargs.get(\"timeline\", Timeline(global_round=1))\n",
        "        stage: TrainingStage = kwargs.get(\"stage\", None)\n",
        "        accuracy = scores[self.ACCURACY]\n",
        "        return {\n",
        "            self.ACCURACY: accuracy\n",
        "        }"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "8e71e0e5-f0af-4d83-afa6-f079c131893a",
        "showInput": false,
        "collapsed": true,
        "id": "8LoKfQhHwwWw"
      },
      "source": [
        "### 3. Hyperparameters\n",
        "\n",
        "We can represent the hyperparameters for FL training in a JSON config.\n",
        "\n",
        "This config is passed to the FL trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3474bdbb-845c-4ad8-837d-e6561001c9ed",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "7ea697a0-0b6b-4d92-86ca-4b40f66915db",
        "executionStartTime": 1636676295041,
        "executionStopTime": 1636676295044,
        "id": "wZOInQQQwwWx"
      },
      "source": [
        "json_config = {\n",
        "    \"trainer\": {\n",
        "        \"_base_\": \"base_sync_trainer\",\n",
        "        # there are different types of aggegator\n",
        "        # fed avg with lr requires a learning rate, wheras e.g. fed_avg doesn't\n",
        "        \"server\": {\n",
        "            \"_base_\": \"base_sync_server\",\n",
        "            \"server_optimizer\": {\n",
        "              \"_base_\": \"base_fed_avg_with_lr\",\n",
        "              # server's learning rate\n",
        "              \"lr\": 0.7,\n",
        "              # server's global momentum\n",
        "              \"momentum\": 1,\n",
        "            },\n",
        "            # aggregate client models using weighted average based on number of \n",
        "            # examples of the local dataset\n",
        "            \"aggregation_type\": \"WEIGHTED_AVERAGE\",\n",
        "            # type of user selection sampling\n",
        "            \"active_user_selector\": {\n",
        "              \"_base_\": \"base_uniformly_random_active_user_selector\"\n",
        "            },\n",
        "        },\n",
        "        \"client\": {\n",
        "            # number of client's local epochs\n",
        "            \"epochs\": 1,\n",
        "            \"optimizer\": {\n",
        "                \"_base_\": \"base_optimizer_sgd\",\n",
        "                # client's local learning rate\n",
        "                \"lr\": 1,\n",
        "                # client's local momentum\n",
        "                \"momentum\": 0,\n",
        "            },\n",
        "        },\n",
        "        # number of users per round for aggregation\n",
        "        \"users_per_round\": 10,\n",
        "        # total number of global epochs\n",
        "        # total #rounds = ceil(total_users / users_per_round) * epochs\n",
        "        \"epochs\": 1,\n",
        "        # frequency of reporting train metrics\n",
        "        \"train_metrics_reported_per_epoch\": 4,\n",
        "        # keep the trained model always (as apposed to only when it\n",
        "        # performs better than the previous model on eval)\n",
        "        \"always_keep_trained_model\": False,\n",
        "        # frequency of evaluation per epoch\n",
        "        \"eval_epoch_frequency\": 1,\n",
        "        \"do_eval\": True,\n",
        "        # should we report train metrics after global aggregation\n",
        "        \"report_train_metrics_after_aggregation\": True,\n",
        "    }\n",
        "}"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "17e85701-f326-48ef-be7e-b5828758510b",
        "showInput": false,
        "id": "lfXJvMB-wwWx"
      },
      "source": [
        "Even though we recommend a JSON config for ease of representation, FLSim is compatible with the Hydra config system and can work with YAML configs just like any other [PyTorch Lightning](https://www.pytorchlightning.ai/) project. Here, we convert the JSON config to OmegaConf via Hydra for consumption by FLSim. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "185bb565-97ec-4b03-a7b4-d899291b8814",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "b7af3119-ea6b-4e88-bcfd-526e980ecb29",
        "executionStartTime": 1636676295049,
        "executionStopTime": 1636676328730,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmbbP-y2wwWx",
        "outputId": "f469f1fd-118c-496b-bbed-37c9f69affef"
      },
      "source": [
        "import flsim.configs\n",
        "from flsim.utils.config_utils import fl_config_from_json\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "\n",
        "cfg = fl_config_from_json(json_config)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/hydra/experimental/initialize.py:36: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
            "  message=\"hydra.experimental.initialize() is no longer experimental.\"\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/experimental/compose.py:19: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
            "  message=\"hydra.experimental.compose() is no longer experimental.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "8ca763b7-c287-4a28-af1a-ca3b7ca5d3e4",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "p-RXOSIpwwWx"
      },
      "source": [
        "### 4. Training\n",
        "Recall that we already built the data provider and created a model compatible with FL training. \n",
        "Now, to launch the FL training flow we only need to take a few more steps:\n",
        "\n",
        "1. First, we need to create a metric reporter, which will collect, evaluate, and report relevent training, aggretaion, and evaluation/test metrics.\n",
        "You can find its implementation [here](https://github.com/facebookresearch/FLSim/blob/main/tutorials/metrics_reporter/fl_metrics_reporter.py).\n",
        "\n",
        "2. We also need to instantiate the trainer with the model and hyperparameter config we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "69332759-76d4-42b9-9de7-70333194b1b6",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "5ee4134f-792d-42db-ba8d-a5864d511dfc",
        "executionStartTime": 1636676328827,
        "executionStopTime": 1636676328872,
        "id": "gVC5pnKTwwWy"
      },
      "source": [
        "from flsim.interfaces.metrics_reporter import Channel\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "# 1. Create a metric reporter.\n",
        "metrics_reporter = MetricsReporter([Channel.TENSORBOARD, Channel.STDOUT])\n",
        "\n",
        "\n",
        "# 2. Instantiate the trainer.\n",
        "trainer_config = cfg.trainer\n",
        "trainer = instantiate(trainer_config, model=global_model, cuda_enabled=cuda_enabled)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "9780a2e9-9af3-4f97-aaaa-dd37457818ca",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "YhDRfzcjwwWy"
      },
      "source": [
        "Finally, we're ready to run FL training given the above JSON config. We can utilize `eval_score` to store the evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9ada7326-5d23-419d-9f7c-58ad678f9f75",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "8e56e399-4b5c-4f0a-92fa-026d46e696cb",
        "executionStopTime": 1636677467749,
        "executionStartTime": 1636676328880,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vd1CKU8wwWy",
        "outputId": "8c909efc-8b12-4004-9a5b-b0e4839827ad"
      },
      "source": [
        "# Launch FL training.\n",
        "final_model, eval_score = trainer.train(\n",
        "    data_provider=data_provider,\n",
        "    metric_reporter=metrics_reporter,\n",
        "    num_total_users=data_provider.num_users(),\n",
        "    distributed_world_size=1,\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Round:   0%|          | 0/577 [00:00<?, ?round/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:692: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:925.)\n",
            "  self.dropout, self.training, self.bidirectional, self.batch_first)\n",
            "Round:  25%|██▌       | 145/577 [00:58<03:03,  2.36round/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 145\n",
            "(epoch = 1, round = 145, global round = 145), Loss/Training: 0.8866520769668088\n",
            "(epoch = 1, round = 145, global round = 145), Accuracy/Training: 50.01446340757882\n",
            "reporting (epoch = 1, round = 145, global round = 145) for aggregation\n",
            "(epoch = 1, round = 145, global round = 145), Loss/Aggregation: 0.8339145928621292\n",
            "(epoch = 1, round = 145, global round = 145), Accuracy/Aggregation: 50.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Round:  50%|█████     | 289/577 [01:57<02:04,  2.31round/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 289\n",
            "(epoch = 1, round = 289, global round = 289), Loss/Training: 1.7769925692442676\n",
            "(epoch = 1, round = 289, global round = 289), Accuracy/Training: 50.197748707027685\n",
            "reporting (epoch = 1, round = 289, global round = 289) for aggregation\n",
            "(epoch = 1, round = 289, global round = 289), Loss/Aggregation: 2.158547518253215\n",
            "(epoch = 1, round = 289, global round = 289), Accuracy/Aggregation: 86.36363636363636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Round:  75%|███████▌  | 433/577 [02:55<01:04,  2.24round/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 433\n",
            "(epoch = 1, round = 433, global round = 433), Loss/Training: 16.83782064347785\n",
            "(epoch = 1, round = 433, global round = 433), Accuracy/Training: 50.70821529745042\n",
            "reporting (epoch = 1, round = 433, global round = 433) for aggregation\n",
            "(epoch = 1, round = 433, global round = 433), Loss/Aggregation: 12.382562828063964\n",
            "(epoch = 1, round = 433, global round = 433), Accuracy/Aggregation: 61.904761904761905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Round: 100%|█████████▉| 576/577 [03:54<00:00,  2.44round/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 577\n",
            "(epoch = 1, round = 577, global round = 577), Loss/Training: 28.58063744585804\n",
            "(epoch = 1, round = 577, global round = 577), Accuracy/Training: 49.727668845315904\n",
            "reporting (epoch = 1, round = 577, global round = 577) for aggregation\n",
            "(epoch = 1, round = 577, global round = 577), Loss/Aggregation: 43.41543006896973\n",
            "(epoch = 1, round = 577, global round = 577), Accuracy/Aggregation: 38.095238095238095\n",
            "Running (epoch = 1, round = 577, global round = 577) for Eval\n",
            "(epoch = 1, round = 577, global round = 577), Loss/Eval: 34.649913735850205\n",
            "(epoch = 1, round = 577, global round = 577), Accuracy/Eval: 50.590687977762336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Round: 100%|█████████▉| 576/577 [03:56<00:00,  2.43round/s]\n",
            "Epoch:   0%|          | 0/1 [03:56<?, ?epoch/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "945fc6b7-a479-4fa1-a75c-3cf241a3f245",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true,
        "id": "KAdEH67NwwWy"
      },
      "source": [
        "After training finishes, we evaluate the model and report the test set accuracy before concluding this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "87a50242-9574-41b3-bf39-6f296f44005e",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "fb7b0794-1455-4805-9e97-c8649d0cb213",
        "executionStartTime": 1636677467822,
        "executionStopTime": 1636677479301,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_8oWt6VwwWy",
        "outputId": "b52025a8-3f43-4abc-925e-a136c8fc5113"
      },
      "source": [
        "# We can now test our model.\n",
        "trainer.test(\n",
        "    data_iter=data_provider.test_data(),\n",
        "    metric_reporter=MetricsReporter([Channel.STDOUT]),\n",
        ")\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running (epoch = 1, round = 1, global round = 1) for Test\n",
            "(epoch = 1, round = 1, global round = 1), Loss/Test: 34.6846507969675\n",
            "(epoch = 1, round = 1, global round = 1), Accuracy/Test: 50.590687977762336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 50.590687977762336}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "835d5964-8dbf-458a-8360-b8cd30f7a4c4",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "fLtYHv8bwwWy"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we first showed how to get and preprocess LEAF's Sent140 dataset. \n",
        "We then built a data provider by splitting each user's data into batches. \n",
        "We defined a simple char-LSTM as our model, wrapped it with a model compatible with FL training, and moved it to GPU. \n",
        "Lastly, we set the hyperparameters for FL training, launched the training flow, and evaluated our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "663d0a7d-dd3c-401f-8f8e-b1db9ffd3cce",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "id": "-LM1ZTdLwwWz"
      },
      "source": [
        "### Additional resources\n",
        "- [FLSim tutorials](https://github.com/facebookresearch/FLSim/tree/main/tutorials) - check out our other tutorial on sentiment classification.\n",
        "- Kairouz et al. (2021): [Advances and Open Problems in Federated Learning](https://arxiv.org/pdf/1912.04977.pdf). As the title suggests, an in-depth overview of advances and open problems in FL.\n",
        "- If you're interested in federated learning with **differential privacy**, take a look at [Opacus](https://opacus.ai/), a library that enables training PyTorch models with differential privacy. \n",
        "You can find a blog post introducing Opacus [here](https://ai.facebook.com/blog/introducing-opacus-a-high-speed-library-for-training-pytorch-models-with-differential-privacy/).\n",
        "\n"
      ]
    }
  ]
}