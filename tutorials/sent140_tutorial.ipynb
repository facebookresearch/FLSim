{
  "metadata": {
    "kernelspec": {
      "display_name": "Python3",
      "language": "python",
      "name": "Python3",
      "metadata": {}
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "4dcf7f7d-d463-42f0-97d7-71e77cdb2b88",
    "last_kernel_id": "a2160017-dec8-4c85-ab1b-725ed083362a",
    "last_base_url": "",
    "last_msg_id": "dcee5f71-a85ac00b09c292d9be063e81_722",
    "captumWidgetMessage": {},
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "ef12966a-7e07-446b-b931-4235e269f994",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "# FLSim Tutorial: Sentiment Classification with LEAF's Sent140\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "669ad0e3-282b-41be-aad0-2c111b3402be",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we will train a binary sentiment classifier on LEAF's Sent140 dataset with federated learning using FLSim. \n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "bcb5f56d-908e-4978-9e60-73c794d1de79",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "To get the most of this tutorial, you should be comfortable training machine learning models with **PyTorch** and familiar with the concept of **federated learning (FL)**. If you are unfamimiliar with either of them or could use a refresher, please take a look at the following resources before proceeding with the tutorial:\n",
        "\n",
        "- McMahan & Ramage (2017): [Federated Learning: Collaborative Machine Learning without Centralized Training Data](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html). A short blog post from Google AI introducing the main idea of FL in a beginner-friendly way.\n",
        "- McMahan et al. (2017): [Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/pdf/1602.05629.pdf). This paper first proposes the approach of federated learning. The described algorithm is now known as federated averaging (or FedAvg for short).\n",
        "- PyTorch has [extensive tutorials](https://pytorch.org/tutorials/) on their website.\n",
        "- If you're new to **sentiment classification**, you can find Pang and Lee's survey on the topic [here](https://www.cs.cornell.edu/home/llee/omsa/omsa-published.pdf). \n",
        "\n",
        "Now that you're familiar with PyTorch and FL and have a sense of sentiment classification, let's move on!"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6c37e934-b30b-4946-8acf-f308b487688f",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to \n",
        "\n",
        "1. Build a data pipeline for federated learning with FLSim,\n",
        "2. Create a sentiment classification model compatible with FL training,\n",
        "3. Set hyperparameters for FL training, and\n",
        "4. Launch an FL training flow using FLSim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "b2a57ec9-bb33-4df6-9608-0abe10445108",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "## Training a sentiment classifier with FLSim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5d2a8203-16cb-492a-a4cd-46b0a9456e21",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "### 0. About the dataset\n",
        "\n",
        "For this tutorial, we're using [LEAF's](https://leaf.cmu.edu/) [Sentiment140 (Sent140) dataset](https://leaf.cmu.edu/build/html/tutorials/sent140-md.html), which consists of 1.6 million tweets by 660k users. Note that the mean number of samples per user is 2.42 and the standard deviation is 4.71.\n",
        "\n",
        "![Sent140 distribution of samples across users](https://leaf.cmu.edu/webpage/images/twitter_hist.png)\n",
        "\n",
        "Before the next step in this tutorial, you need to download the dataset and partition the data by users. \n",
        "We've included a script, `get_data.sh`, which will download and preproces the data for you. \n",
        "In particular, we sample 1% of the entire dataset in a non-IID manner and\n",
        "partition 90% of sampled users into train and 10% of sampled users into test (as opposed to individual samples).\n",
        "We require all users to have at least one sample.\n",
        "\n",
        "For more information on the various preprocessing options, see [here](https://github.com/TalwalkarLab/leaf/tree/master/data/sent140). You can find the LEAF paper [here](https://arxiv.org/pdf/1812.01097.pdf).\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "59d5e611-102e-4d44-9478-cfd54f0ca81b",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5ab54fa9-8358-41b9-91c5-ed36729a10b2",
        "executionStartTime": 1636676289207,
        "executionStopTime": 1636676290023
      },
      "source": [
        "%cd ~/local\n",
        "!sh FLSim/tutorials/get_data.sh"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/data/users/jessicazhao\nfatal: destination path 'leaf' already exists and is not an empty directory.\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\r\ncalculating JSON file checksums\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checksums written to meta/dir-checksum.md5\r\nData for one of the specified preprocessing tasks has already been\r\ngenerated. If you would like to re-generate data for this directory,\r\nplease delete the existing one. Otherwise, please remove the\r\nrespective tag(s) from the preprocessing command.\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "6d9d0efd-fcaa-4017-beb6-c9da31b4094e",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "We can find the preprocessed training and test data here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d3836318-4ccb-4fbd-bd33-af77d6b72d17",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "92a8c570-a267-45c6-b2d1-950fde49c110",
        "executionStartTime": 1636676290126,
        "executionStopTime": 1636676290307
      },
      "source": [
        "!ls leaf/data/sent140/data/train; ls leaf/data/sent140/data/test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_data_0_01_keep_1_train_9.json\r\nall_data_0_01_keep_1_test_9.json\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "72744006-8d85-4ab0-b377-2572ae84bd25",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Note: if you use different preprocessing options, you will need to change these!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a27a936f-9c09-4884-a792-0cd118687116",
        "showInput": true,
        "collapsed": false,
        "requestMsgId": "4fb9c5e3-9a89-4081-b589-f9e1286bce9e",
        "executionStartTime": 1636676290310,
        "executionStopTime": 1636676290315,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "TRAIN_DATA = \"leaf/data/sent140/data/train/all_data_0_01_keep_1_train_9.json\"\n",
        "TEST_DATA = \"leaf/data/sent140/data/test/all_data_0_01_keep_1_test_9.json\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "20691777-83ab-4406-84c5-950fa4b2224f",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "We can now get a rough idea of the structure of the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8cc146cc-61db-445c-9c8c-8528226d3b80",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "26f25906-c0a5-43fe-a025-e4b39a598570",
        "executionStartTime": 1636676290335,
        "executionStopTime": 1636676290360
      },
      "source": [
        "import json\n",
        "\n",
        "\n",
        "with open(TRAIN_DATA, \"r\") as f:\n",
        "    training_data = json.load(f)\n",
        "\n",
        "    # get overall structure of the data\n",
        "    for key, val in training_data.items():\n",
        "        print(key, type(val), len(val))\n",
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "users <class 'list'> 6008\nnum_samples <class 'list'> 6008\nuser_data <class 'dict'> 6008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "2b202d71-bac7-43d3-943b-f4b8a5f391a6",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "We can compute the minimum, maximum, and mean number of samples per user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e774e6c4-91b0-4da0-9632-17f891980d44",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "06ec3dbb-2ed1-4551-9861-f8f580401549",
        "executionStartTime": 1636676290379,
        "executionStopTime": 1636676290383
      },
      "source": [
        "print(f\"Min # samples per user: {min(training_data['num_samples'])}\")\n",
        "print(f\"Max # samples per user: {max(training_data['num_samples'])}\")\n",
        "print(\n",
        "    f\"Mean # samples per user: {round(sum(training_data['num_samples'])/len(training_data['num_samples']), 2)}\"\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min # samples per user: 1\nMax # samples per user: 87\nMean # samples per user: 2.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "d596da87-913c-4079-8d81-65914d0665db",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Let us also look at the data for an example user:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4d8c298b-b1c4-48e9-bf09-0217abe97393",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a706da0d-e298-4e63-b2c0-c5ac97a43f64",
        "executionStartTime": 1636676290400,
        "executionStopTime": 1636676290432
      },
      "source": [
        "EXAMPLE_USER = training_data[\"users\"][0]\n",
        "training_data[\"user_data\"][EXAMPLE_USER]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'x': [['1882285552',\n   'Fri May 22 06:35:30 PDT 2009',\n   'NO_QUERY',\n   'abbyyyoung',\n   \"@michaelaline I want a pair real bad too!  TOM'S are awesome.\",\n   'training']],\n 'y': [1]}"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "7152ba71-9205-408c-a369-00308e75314a",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "### 1. Data pipeline\n",
        "\n",
        "Now, let us define how to build the data pipeline for federated learning:\n",
        "\n",
        "1. To load the training and test data, we define a new dataset class, `Sent140Dataset`, which converts each user's tweets (features) into a `torch.Tensor`, discarding tweet metadata such as time, and stores each tweet's sentiment (label) as well.\n",
        "\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "77651659-ce0a-48ef-947b-ca898bb3793f",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "791e752f-82c1-444d-9ced-3716af1460c9",
        "executionStartTime": 1636676290438,
        "executionStopTime": 1636676291421
      },
      "source": [
        "import itertools\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# 1. Sent140Dataset will store the tweets and corresponding sentiment for each user.\n",
        "\n",
        "\n",
        "class Sent140Dataset(Dataset):\n",
        "    def __init__(self, data_root, max_seq_len):\n",
        "        self.data_root = data_root\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.all_letters = {c: i for i, c in enumerate(string.printable)}\n",
        "        self.num_letters = len(self.all_letters)\n",
        "        self.UNK = self.num_letters\n",
        "\n",
        "        with open(data_root, \"r+\") as f:\n",
        "            self.dataset = json.load(f)\n",
        "\n",
        "        self.data = {}\n",
        "        self.targets = {}\n",
        "\n",
        "        self.num_classes = 2  # binary sentiment classification\n",
        "\n",
        "        # Populate self.data and self.targets\n",
        "        for user_id, user_data in self.dataset[\"user_data\"].items():\n",
        "            self.data[user_id] = self.process_x(list(user_data[\"x\"]))\n",
        "            self.targets[user_id] = self.process_y(list(user_data[\"y\"]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for user_id in self.data.keys():\n",
        "            yield self.__getitem__(user_id)\n",
        "\n",
        "    def __getitem__(self, user_id: str):\n",
        "        if user_id not in self.data or user_id not in self.targets:\n",
        "            raise IndexError(f\"User {user_id} is not in dataset\")\n",
        "\n",
        "        return self.data[user_id], self.targets[user_id]\n",
        "\n",
        "    def unicodeToAscii(self, s):\n",
        "        return \"\".join(\n",
        "            c\n",
        "            for c in unicodedata.normalize(\"NFD\", s)\n",
        "            if unicodedata.category(c) != \"Mn\" and c in self.all_letters\n",
        "        )\n",
        "\n",
        "    def line_to_indices(self, line: str, max_seq_len: int):\n",
        "        line_list = self.split_line(line)  # split phrase in words\n",
        "        line_list = line_list\n",
        "        chars = self.flatten_list([list(word) for word in line_list])\n",
        "        indices = [\n",
        "            self.all_letters.get(letter, self.UNK)\n",
        "            for i, letter in enumerate(chars)\n",
        "            if i < max_seq_len\n",
        "        ]\n",
        "        # Add padding\n",
        "        indices = indices + [self.UNK] * (max_seq_len - len(indices))\n",
        "        return indices\n",
        "\n",
        "    def process_x(self, raw_x_batch):\n",
        "        x_batch = [e[4] for e in raw_x_batch]  # e[4] contains the actual tweet\n",
        "        x_batch = [self.line_to_indices(e, self.max_seq_len) for e in x_batch]\n",
        "        x_batch = torch.LongTensor(x_batch)\n",
        "        return x_batch\n",
        "\n",
        "    def process_y(self, raw_y_batch):\n",
        "        y_batch = [int(e) for e in raw_y_batch]\n",
        "        return y_batch\n",
        "\n",
        "    def split_line(self, line):\n",
        "        \"\"\"\n",
        "        Split given line/phrase into list of words\n",
        "\n",
        "        Args:\n",
        "            line: string representing phrase to be split\n",
        "\n",
        "        Return:\n",
        "            list of strings, with each string representing a word\n",
        "        \"\"\"\n",
        "        return re.findall(r\"[\\w']+|[.,!?;]\", line)\n",
        "\n",
        "    def flatten_list(self, nested_list):\n",
        "        return list(itertools.chain.from_iterable(nested_list))\n",
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "f76ded33-fb91-4978-96ce-da9a65d8c7dc",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "2. We can now load the train and test dataset.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4f2e40f3-8e8d-4590-803a-6210cd4455c4",
        "showInput": true,
        "collapsed": false,
        "requestMsgId": "5b6ad058-f5e0-4616-a05c-b9c1ec19fb01",
        "executionStartTime": 1636676291516,
        "executionStopTime": 1636676292257,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "MAX_SEQ_LEN = 25\n",
        "\n",
        "\n",
        "# 2. Load the train and test datasets.\n",
        "train_dataset = Sent140Dataset(\n",
        "    data_root=TRAIN_DATA,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        ")\n",
        "test_dataset = Sent140Dataset(\n",
        "    data_root=TEST_DATA,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        ")\n",
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "63946b49-8f29-473a-a694-4aa68e982593",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Recall our `EXAMPLE_USER` from earlier? Their data now looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8c2b0f96-2836-42b5-9d3b-cc468fb20a7a",
        "showInput": true,
        "collapsed": false,
        "requestMsgId": "0ecb6209-5c9c-45a3-adb7-1abb17865411",
        "executionStartTime": 1636676292269,
        "executionStopTime": 1636676292273,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "train_dataset[EXAMPLE_USER]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([[22, 18, 12, 17, 10, 14, 21, 10, 21, 18, 23, 14, 44, 32, 10, 23, 29, 10,\n          25, 10, 18, 27, 27, 14, 10]]),\n [1])"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "dd5a34ad-bf41-4b6b-82db-8dc528131310",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "To complete our data pipeline, we only need to\n",
        "\n",
        "3. Create a data loader, which will batchify training, eval, and test data. There is no need to create a sharder since the data is already sharded. For each dataset, the data loader splits each client's data into batches of size `batch_size`. We choose not to drop the last batch.\n",
        "\n",
        "4. Lastly, wrap the data loader with a data provider and return it. \n",
        "The data provider creates clients from the groupings in the data loader and adds metadata (e.g. number of examples, number of batches per client). \n",
        "Our data is now formatted such that the trainer will accept it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "09659734-9020-4f0e-a01f-4491a8f700c8",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "52557db1-39c7-4695-b7c6-f3ac73ad8a0c",
        "executionStartTime": 1636676292361,
        "executionStopTime": 1636676295007
      },
      "source": [
        "from flsim.baselines.data_providers import LEAFDataLoader, LEAFDataProvider\n",
        "\n",
        "\n",
        "# 3. Batchify training, eval, and test data. Note that train_dataset is already sharded.\n",
        "dataloader = LEAFDataLoader(\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "# 4. Wrap the data loader with a data provider.\n",
        "data_provider = LEAFDataProvider(dataloader)\n",
        ""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCreating FL User: 0user [00:00, ?user/s]",
            "\rCreating FL User: 925user [00:00, 9243.05user/s]",
            "\rCreating FL User: 1881user [00:00, 9428.60user/s]",
            "\rCreating FL User: 2824user [00:00, 9356.97user/s]",
            "\rCreating FL User: 3760user [00:00, 9317.52user/s]",
            "\rCreating FL User: 4703user [00:00, 9351.32user/s]",
            "\rCreating FL User: 5639user [00:00, 9286.32user/s]",
            "\rCreating FL User: 6008user [00:00, 9331.22user/s]",
            "\n\rCreating FL User: 0user [00:00, ?user/s]",
            "\rCreating FL User: 668user [00:00, 9436.61user/s]",
            "\n\rCreating FL User: 0user [00:00, ?user/s]",
            "\rCreating FL User: 668user [00:00, 9783.38user/s]",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "85636a6d-4c4b-49ea-9e82-34b3a9ddcbb3",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "### 2. Create the model\n",
        "\n",
        "Now, let's see how we can create a model that is compatible with FL-training.\n",
        "\n",
        "1. First, we define a standard, non-FL sentiment classification pytorch `nn.Module`; in this tutorial we use a simple char-LSTM."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "257233d5-1f9f-47e3-8b1b-63ea4060e0c2",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "e74219b0-4bc2-4520-ba01-e0650091ca80",
        "executionStartTime": 1636676295011,
        "executionStopTime": 1636676295015
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "# 1. Define our model, a simple char-LSTM.\n",
        "\n",
        "class CharLSTM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes,\n",
        "        n_hidden,\n",
        "        num_embeddings,\n",
        "        embedding_dim,\n",
        "        max_seq_len,\n",
        "        dropout_rate,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.n_hidden = n_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_embeddings = num_embeddings\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=self.num_embeddings, embedding_dim=embedding_dim\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=self.n_hidden,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout_rate,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.n_hidden, self.num_classes)\n",
        "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_lens = torch.sum(x != (self.num_embeddings - 1), 1) - 1\n",
        "        x = self.embedding(x)  # [B, S] -> [B, S, E]\n",
        "        out, _ = self.lstm(x)  # [B, S, E] -> [B, S, H]\n",
        "        out = out[torch.arange(out.size(0)), seq_lens]\n",
        "        out = self.fc(self.dropout(out))  # [B, S, H] -> # [B, S, C]\n",
        "        return out\n",
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "e78f06ab-88a9-44e9-b8f8-5c8ced763143",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "We initialize our model wich such parameters that it is compatible with our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "24f03560-4a92-4f0c-8ad6-98568144a441",
        "showInput": true,
        "collapsed": false,
        "requestMsgId": "ca0a4f69-053e-4149-87c8-b9c037ad9027",
        "executionStartTime": 1636676295021,
        "executionStopTime": 1636676295027,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "model = CharLSTM(\n",
        "    num_classes=train_dataset.num_classes,\n",
        "    n_hidden=100,\n",
        "    num_embeddings=train_dataset.num_letters + 1,\n",
        "    embedding_dim=100,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    dropout_rate=0.1,\n",
        ")\n",
        "\n",
        "model\n",
        ""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "CharLSTM(\n  (embedding): Embedding(101, 100)\n  (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.1)\n  (fc): Linear(in_features=100, out_features=2, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "37dd6b2d-f4e1-49bb-b13f-7e6e74f9339e",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "After we have our standard PyTorch model, we can\n",
        "\n",
        "2. Create a `torch.device` and choose where the model will be allocated (CUDA or CPU). \n",
        "\n",
        "3. Wrap the pytorch module with the FLSim `FLModel`. `FLModel` is accepted by the trainer and handles moving our model, data, and predictions to GPU if desired. It also collects and returns metrics for each batch it predicts on. You can find its implementation [here](https://github.com/facebookresearch/FLSim/blob/main/baselines/models/cv_model.py)\n",
        "\n",
        "4. Move the model to GPU and enable CUDA if desired.\n",
        "\n",
        "The model now supports FL training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f5a19f8d-34ca-4342-98e3-c68ea9ae7e0d",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2f20621b-5f97-4396-adb5-e04ca2cebd92",
        "executionStartTime": 1636676295032,
        "executionStopTime": 1636676295038
      },
      "source": [
        "import torch\n",
        "from flsim.baselines.models.cv_model import FLModel\n",
        "\n",
        "\n",
        "USE_CUDA = True\n",
        "\n",
        "# 2. Choose where the model will be allocated.\n",
        "cuda_enabled = torch.cuda.is_available() and USE_CUDA\n",
        "device = torch.device(f\"cuda:{0}\" if cuda_enabled else \"cpu\")\n",
        "\n",
        "# 3. Wrap the model in FLModel.\n",
        "global_model = FLModel(model, device)\n",
        "\n",
        "# 4. Enable CUDA if desired.\n",
        "if cuda_enabled:\n",
        "    global_model.fl_cuda()\n",
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "8e71e0e5-f0af-4d83-afa6-f079c131893a",
        "showInput": false,
        "collapsed": true
      },
      "source": [
        "### 3. Hyperparameters\n",
        "\n",
        "We can represent the hyperparameters for FL training in a JSON config.\n",
        "\n",
        "This config is passed to the FL trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3474bdbb-845c-4ad8-837d-e6561001c9ed",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7ea697a0-0b6b-4d92-86ca-4b40f66915db",
        "executionStartTime": 1636676295041,
        "executionStopTime": 1636676295044
      },
      "source": [
        "json_config = {\n",
        "    \"trainer\": {\n",
        "        \"_base_\": \"base_sync_trainer\",\n",
        "        # there are different types of aggegator\n",
        "        # fed avg with lr requires a learning rate, wheras e.g. fed_avg doesn't\n",
        "        \"aggregator\": {\n",
        "            \"_base_\": \"base_fed_avg_with_lr_sync_aggregator\",\n",
        "            # server's learning rate\n",
        "            \"lr\": 0.7,\n",
        "            # server's global momentum\n",
        "            \"momentum\": 1,\n",
        "            # reduce client models into a single model by taking their weighted sum\n",
        "            \"reducer\": {\"_base_\": \"base_reducer\", \"reduction_type\": \"WEIGHTED_SUM\"},\n",
        "        },\n",
        "        \"client\": {\n",
        "            # number of client's local epochs\n",
        "            \"epochs\": 1,\n",
        "            \"optimizer\": {\n",
        "                \"_base_\": \"base_optimizer_sgd\",\n",
        "                # client's local learning rate\n",
        "                \"lr\": 1,\n",
        "                # client's local momentum\n",
        "                \"momentum\": 0,\n",
        "            },\n",
        "            \"lr_scheduler\": {\n",
        "                # normalize the learning rate by the number of examples in the batch\n",
        "                \"_base_\": \"base_lr_batch_size_normalizer_scheduler\",\n",
        "                \"local_lr_normalizer\": 32,\n",
        "            },\n",
        "        },\n",
        "        # type of user selection sampling\n",
        "        \"active_user_selector\": {\n",
        "            \"_base_\": \"base_uniformly_random_active_user_selector\"\n",
        "        },\n",
        "        # number of users per round for aggregation\n",
        "        \"users_per_round\": 10,\n",
        "        # total number of global epochs\n",
        "        # total #rounds = ceil(total_users / users_per_round) * epochs\n",
        "        \"epochs\": 1,\n",
        "        # frequency of reporting train metrics\n",
        "        \"train_metrics_reported_per_epoch\": 4,\n",
        "        # keep the trained model always (as apposed to only when it\n",
        "        # performs better than the previous model on eval)\n",
        "        \"always_keep_trained_model\": False,\n",
        "        # frequency of evaluation per epoch\n",
        "        \"eval_epoch_frequency\": 1,\n",
        "        \"do_eval\": True,\n",
        "        # should we report train metrics after global aggregation\n",
        "        \"report_train_metrics_after_aggregation\": True,\n",
        "    }\n",
        "}\n",
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "17e85701-f326-48ef-be7e-b5828758510b",
        "showInput": false
      },
      "source": [
        "Even though we recommend a JSON config for ease of representation, FLSim is compatible with the Hydra config system and can work with YAML configs just like any other [PyTorch Lightning](https://www.pytorchlightning.ai/) project. Here, we convert the JSON config to OmegaConf via Hydra for consumption by FLSim. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "185bb565-97ec-4b03-a7b4-d899291b8814",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b7af3119-ea6b-4e88-bcfd-526e980ecb29",
        "executionStartTime": 1636676295049,
        "executionStopTime": 1636676328730
      },
      "source": [
        "import flsim.configs\n",
        "from flsim.utils.config_utils import fl_config_from_json\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "\n",
        "cfg = fl_config_from_json(json_config)\n",
        "print(OmegaConf.to_yaml(cfg))\n",
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer:\n  _target_: flsim.trainers.sync_trainer.SyncTrainer\n  _recursive_: false\n  epochs: 1.0\n  do_eval: true\n  always_keep_trained_model: false\n  timeout_simulator:\n    _target_: ???\n    _recursive_: false\n  train_metrics_reported_per_epoch: 4\n  eval_epoch_frequency: 1.0\n  active_user_selector:\n    _target_: flsim.active_user_selectors.simple_user_selector.UniformlyRandomActiveUserSelector\n    _recursive_: false\n    user_selector_seed: null\n    random_with_replacement: false\n  report_train_metrics: true\n  report_train_metrics_after_aggregation: true\n  use_train_clients_for_aggregation_metrics: true\n  client:\n    _target_: flsim.clients.base_client.Client\n    _recursive_: false\n    epochs: 1\n    optimizer:\n      _target_: flsim.optimizers.local_optimizers.LocalOptimizerSGD\n      _recursive_: false\n      lr: 1.0\n      momentum: 0.0\n      weight_decay: 0.0\n    lr_scheduler:\n      _target_: flsim.optimizers.optimizer_scheduler.LRBatchSizeNormalizer\n      _recursive_: false\n      base_lr: 0.001\n      local_lr_normalizer: 32\n    max_clip_norm_normalized: null\n    only_federated_params: true\n    random_seed: null\n    shuffle_batch_order: false\n    store_models_and_optimizers: false\n    track_multiple_selection: false\n  channel:\n    _target_: flsim.channels.base_channel.IdentityChannel\n    _recursive_: false\n  report_communication_metrics: false\n  aggregator:\n    _target_: flsim.optimizers.sync_aggregators.FedAvgWithLRSyncAggregator\n    _recursive_: false\n    reducer:\n      _target_: flsim.reducers.base_round_reducer.RoundReducer\n      _recursive_: false\n      only_federated_params: true\n      reduction_type: WEIGHTED_SUM\n      precision: DEFAULT\n    num_users_per_round: 1\n    total_number_of_users: 10000000000\n    lr: 0.7\n    momentum: 1.0\n  users_per_round: 10\n  dropout_rate: 1.0\n  report_client_metrics_after_epoch: false\n  report_client_metrics: false\n  client_metrics_reported_per_epoch: 1\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "8ca763b7-c287-4a28-af1a-ca3b7ca5d3e4",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "### 4. Training\n",
        "Recall that we already built the data provider and created a model compatible with FL training. \n",
        "Now, to launch the FL training flow we only need to take a few more steps:\n",
        "\n",
        "1. First, we need to create a metric reporter, which will collect, evaluate, and report relevent training, aggretaion, and evaluation/test metrics.\n",
        "You can find its implementation [here](https://github.com/facebookresearch/FLSim/blob/main/tutorials/metrics_reporter/fl_metrics_reporter.py).\n",
        "\n",
        "2. We also need to instantiate the trainer with the model and hyperparameter config we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "69332759-76d4-42b9-9de7-70333194b1b6",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5ee4134f-792d-42db-ba8d-a5864d511dfc",
        "executionStartTime": 1636676328827,
        "executionStopTime": 1636676328872
      },
      "source": [
        "from flsim.interfaces.metrics_reporter import Channel\n",
        "from flsim.tutorials.metrics_reporter.fl_metrics_reporter import MetricsReporter\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "\n",
        "# 1. Create a metric reporter.\n",
        "metrics_reporter = MetricsReporter([Channel.TENSORBOARD, Channel.STDOUT])\n",
        "\n",
        "\n",
        "# 2. Instantiate the trainer.\n",
        "trainer_config = cfg.trainer\n",
        "trainer = instantiate(trainer_config, model=global_model, cuda_enabled=cuda_enabled)\n",
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "9780a2e9-9af3-4f97-aaaa-dd37457818ca",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "Finally, we're ready to run FL training given the above JSON config. We can utilize `eval_score` to store the evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9ada7326-5d23-419d-9f7c-58ad678f9f75",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8e56e399-4b5c-4f0a-92fa-026d46e696cb",
        "executionStopTime": 1636677467749,
        "executionStartTime": 1636676328880
      },
      "source": [
        "# Launch FL training.\n",
        "final_model, eval_score = trainer.train(\n",
        "    data_provider=data_provider,\n",
        "    metric_reporter=metrics_reporter,\n",
        "    num_total_users=data_provider.num_users(),\n",
        "    distributed_world_size=1,\n",
        ")\n",
        ""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/1 [00:00<?, ?epoch/s]",
            "\rRound:   0%|          | 0/601 [00:00<?, ?round/s]",
            "\rRound:   0%|          | 1/601 [00:03<31:17,  3.13s/round]",
            "\rRound:   0%|          | 2/601 [00:04<20:24,  2.04s/round]",
            "\rRound:   0%|          | 3/601 [00:06<19:28,  1.95s/round]",
            "\rRound:   1%|          | 4/601 [00:08<19:10,  1.93s/round]",
            "\rRound:   1%|          | 5/601 [00:09<16:33,  1.67s/round]",
            "\rRound:   1%|          | 6/601 [00:10<14:51,  1.50s/round]",
            "\rRound:   1%|          | 7/601 [00:11<13:27,  1.36s/round]",
            "\rRound:   1%|▏         | 8/601 [00:12<12:33,  1.27s/round]",
            "\rRound:   1%|▏         | 9/601 [00:13<12:29,  1.27s/round]",
            "\rRound:   2%|▏         | 10/601 [00:15<12:03,  1.22s/round]",
            "\rRound:   2%|▏         | 11/601 [00:16<11:21,  1.16s/round]",
            "\rRound:   2%|▏         | 12/601 [00:18<15:18,  1.56s/round]",
            "\rRound:   2%|▏         | 13/601 [00:21<20:10,  2.06s/round]",
            "\rRound:   2%|▏         | 14/601 [00:24<22:40,  2.32s/round]",
            "\rRound:   2%|▏         | 15/601 [00:28<28:23,  2.91s/round]",
            "\rRound:   3%|▎         | 16/601 [00:31<26:14,  2.69s/round]",
            "\rRound:   3%|▎         | 17/601 [00:35<31:13,  3.21s/round]",
            "\rRound:   3%|▎         | 18/601 [00:39<33:31,  3.45s/round]",
            "\rRound:   3%|▎         | 19/601 [00:45<39:32,  4.08s/round]",
            "\rRound:   3%|▎         | 20/601 [00:47<35:05,  3.62s/round]",
            "\rRound:   3%|▎         | 21/601 [00:50<32:21,  3.35s/round]",
            "\rRound:   4%|▎         | 22/601 [00:53<31:08,  3.23s/round]",
            "\rRound:   4%|▍         | 23/601 [00:56<30:20,  3.15s/round]",
            "\rRound:   4%|▍         | 24/601 [00:58<28:51,  3.00s/round]",
            "\rRound:   4%|▍         | 25/601 [01:02<29:34,  3.08s/round]",
            "\rRound:   4%|▍         | 26/601 [01:05<30:00,  3.13s/round]",
            "\rRound:   4%|▍         | 27/601 [01:08<28:54,  3.02s/round]",
            "\rRound:   5%|▍         | 28/601 [01:11<28:19,  2.97s/round]",
            "\rRound:   5%|▍         | 29/601 [01:14<28:36,  3.00s/round]",
            "\rRound:   5%|▍         | 30/601 [01:17<29:38,  3.11s/round]",
            "\rRound:   5%|▌         | 31/601 [01:20<28:31,  3.00s/round]",
            "\rRound:   5%|▌         | 32/601 [01:23<28:16,  2.98s/round]",
            "\rRound:   5%|▌         | 33/601 [01:25<25:34,  2.70s/round]",
            "\rRound:   6%|▌         | 34/601 [01:27<24:06,  2.55s/round]",
            "\rRound:   6%|▌         | 35/601 [01:33<34:16,  3.63s/round]",
            "\rRound:   6%|▌         | 36/601 [01:35<30:43,  3.26s/round]",
            "\rRound:   6%|▌         | 37/601 [01:38<28:02,  2.98s/round]",
            "\rRound:   6%|▋         | 38/601 [01:40<26:51,  2.86s/round]",
            "\rRound:   6%|▋         | 39/601 [01:43<25:33,  2.73s/round]",
            "\rRound:   7%|▋         | 40/601 [01:45<24:11,  2.59s/round]",
            "\rRound:   7%|▋         | 41/601 [01:48<26:05,  2.80s/round]",
            "\rRound:   7%|▋         | 42/601 [01:53<30:20,  3.26s/round]",
            "\rRound:   7%|▋         | 43/601 [01:55<26:57,  2.90s/round]",
            "\rRound:   7%|▋         | 44/601 [01:56<23:00,  2.48s/round]",
            "\rRound:   7%|▋         | 45/601 [01:58<20:43,  2.24s/round]",
            "\rRound:   8%|▊         | 46/601 [02:02<25:22,  2.74s/round]",
            "\rRound:   8%|▊         | 47/601 [02:05<25:27,  2.76s/round]",
            "\rRound:   8%|▊         | 48/601 [02:08<26:02,  2.83s/round]",
            "\rRound:   8%|▊         | 49/601 [02:11<26:33,  2.89s/round]",
            "\rRound:   8%|▊         | 50/601 [02:13<23:57,  2.61s/round]",
            "\rRound:   8%|▊         | 51/601 [02:15<24:04,  2.63s/round]",
            "\rRound:   9%|▊         | 52/601 [02:17<21:55,  2.40s/round]",
            "\rRound:   9%|▉         | 53/601 [02:19<19:28,  2.13s/round]",
            "\rRound:   9%|▉         | 54/601 [02:21<20:15,  2.22s/round]",
            "\rRound:   9%|▉         | 55/601 [02:24<21:29,  2.36s/round]",
            "\rRound:   9%|▉         | 56/601 [02:26<21:25,  2.36s/round]",
            "\rRound:   9%|▉         | 57/601 [02:29<23:59,  2.65s/round]",
            "\rRound:  10%|▉         | 58/601 [02:35<31:20,  3.46s/round]",
            "\rRound:  10%|▉         | 59/601 [02:38<30:53,  3.42s/round]",
            "\rRound:  10%|▉         | 60/601 [02:40<27:18,  3.03s/round]",
            "\rRound:  10%|█         | 61/601 [02:43<27:29,  3.06s/round]",
            "\rRound:  10%|█         | 62/601 [02:46<27:02,  3.01s/round]",
            "\rRound:  10%|█         | 63/601 [02:49<25:42,  2.87s/round]",
            "\rRound:  11%|█         | 64/601 [02:51<23:56,  2.68s/round]",
            "\rRound:  11%|█         | 65/601 [02:52<20:34,  2.30s/round]",
            "\rRound:  11%|█         | 66/601 [02:55<20:25,  2.29s/round]",
            "\rRound:  11%|█         | 67/601 [02:57<20:46,  2.33s/round]",
            "\rRound:  11%|█▏        | 68/601 [03:01<24:01,  2.70s/round]",
            "\rRound:  11%|█▏        | 69/601 [03:03<23:19,  2.63s/round]",
            "\rRound:  12%|█▏        | 70/601 [03:05<20:43,  2.34s/round]",
            "\rRound:  12%|█▏        | 71/601 [03:07<20:03,  2.27s/round]",
            "\rRound:  12%|█▏        | 72/601 [03:10<22:21,  2.54s/round]",
            "\rRound:  12%|█▏        | 73/601 [03:15<28:39,  3.26s/round]",
            "\rRound:  12%|█▏        | 74/601 [03:18<27:53,  3.18s/round]",
            "\rRound:  12%|█▏        | 75/601 [03:21<26:48,  3.06s/round]",
            "\rRound:  13%|█▎        | 76/601 [03:27<34:26,  3.94s/round]",
            "\rRound:  13%|█▎        | 77/601 [03:31<36:06,  4.13s/round]",
            "\rRound:  13%|█▎        | 78/601 [03:35<33:26,  3.84s/round]",
            "\rRound:  13%|█▎        | 79/601 [03:37<28:36,  3.29s/round]",
            "\rRound:  13%|█▎        | 80/601 [03:38<24:47,  2.86s/round]",
            "\rRound:  13%|█▎        | 81/601 [03:40<22:12,  2.56s/round]",
            "\rRound:  14%|█▎        | 82/601 [03:44<24:34,  2.84s/round]",
            "\rRound:  14%|█▍        | 83/601 [03:48<27:13,  3.15s/round]",
            "\rRound:  14%|█▍        | 84/601 [03:51<27:43,  3.22s/round]",
            "\rRound:  14%|█▍        | 85/601 [03:53<24:51,  2.89s/round]",
            "\rRound:  14%|█▍        | 86/601 [03:55<22:01,  2.57s/round]",
            "\rRound:  14%|█▍        | 87/601 [03:58<22:38,  2.64s/round]",
            "\rRound:  15%|█▍        | 88/601 [04:01<24:29,  2.87s/round]",
            "\rRound:  15%|█▍        | 89/601 [04:04<23:26,  2.75s/round]",
            "\rRound:  15%|█▍        | 90/601 [04:08<27:04,  3.18s/round]",
            "\rRound:  15%|█▌        | 91/601 [04:11<27:33,  3.24s/round]",
            "\rRound:  15%|█▌        | 92/601 [04:14<26:35,  3.13s/round]",
            "\rRound:  15%|█▌        | 93/601 [04:18<27:53,  3.29s/round]",
            "\rRound:  16%|█▌        | 94/601 [04:21<28:04,  3.32s/round]",
            "\rRound:  16%|█▌        | 95/601 [04:24<25:58,  3.08s/round]",
            "\rRound:  16%|█▌        | 96/601 [04:28<28:44,  3.41s/round]",
            "\rRound:  16%|█▌        | 97/601 [04:31<27:02,  3.22s/round]",
            "\rRound:  16%|█▋        | 98/601 [04:35<28:53,  3.45s/round]",
            "\rRound:  16%|█▋        | 99/601 [04:38<29:02,  3.47s/round]",
            "\rRound:  17%|█▋        | 100/601 [04:42<29:46,  3.56s/round]",
            "\rRound:  17%|█▋        | 101/601 [04:45<29:22,  3.53s/round]",
            "\rRound:  17%|█▋        | 102/601 [04:47<25:36,  3.08s/round]",
            "\rRound:  17%|█▋        | 103/601 [04:52<30:13,  3.64s/round]",
            "\rRound:  17%|█▋        | 104/601 [04:55<28:57,  3.50s/round]",
            "\rRound:  17%|█▋        | 105/601 [04:58<27:02,  3.27s/round]",
            "\rRound:  18%|█▊        | 106/601 [05:04<32:41,  3.96s/round]",
            "\rRound:  18%|█▊        | 107/601 [05:07<30:46,  3.74s/round]",
            "\rRound:  18%|█▊        | 108/601 [05:10<29:38,  3.61s/round]",
            "\rRound:  18%|█▊        | 109/601 [05:13<26:58,  3.29s/round]",
            "\rRound:  18%|█▊        | 110/601 [05:18<30:26,  3.72s/round]",
            "\rRound:  18%|█▊        | 111/601 [05:24<36:21,  4.45s/round]",
            "\rRound:  19%|█▊        | 112/601 [05:27<34:05,  4.18s/round]",
            "\rRound:  19%|█▉        | 113/601 [05:30<29:34,  3.64s/round]",
            "\rRound:  19%|█▉        | 114/601 [05:32<26:13,  3.23s/round]",
            "\rRound:  19%|█▉        | 115/601 [05:35<24:35,  3.04s/round]",
            "\rRound:  19%|█▉        | 116/601 [05:38<25:28,  3.15s/round]",
            "\rRound:  19%|█▉        | 117/601 [05:41<25:27,  3.16s/round]",
            "\rRound:  20%|█▉        | 118/601 [05:44<25:25,  3.16s/round]",
            "\rRound:  20%|█▉        | 119/601 [05:48<26:09,  3.26s/round]",
            "\rRound:  20%|█▉        | 120/601 [05:51<25:41,  3.20s/round]",
            "\rRound:  20%|██        | 121/601 [05:53<22:59,  2.87s/round]",
            "\rRound:  20%|██        | 122/601 [05:56<22:11,  2.78s/round]",
            "\rRound:  20%|██        | 123/601 [05:58<21:57,  2.76s/round]",
            "\rRound:  21%|██        | 124/601 [06:00<20:02,  2.52s/round]",
            "\rRound:  21%|██        | 125/601 [06:03<21:26,  2.70s/round]",
            "\rRound:  21%|██        | 126/601 [06:05<19:51,  2.51s/round]",
            "\rRound:  21%|██        | 127/601 [06:10<24:36,  3.11s/round]",
            "\rRound:  21%|██▏       | 128/601 [06:16<31:20,  3.98s/round]",
            "\rRound:  21%|██▏       | 129/601 [06:20<30:37,  3.89s/round]",
            "\rRound:  22%|██▏       | 130/601 [06:23<29:05,  3.71s/round]",
            "\rRound:  22%|██▏       | 131/601 [06:28<31:59,  4.08s/round]",
            "\rRound:  22%|██▏       | 132/601 [06:31<29:05,  3.72s/round]",
            "\rRound:  22%|██▏       | 133/601 [06:34<28:43,  3.68s/round]",
            "\rRound:  22%|██▏       | 134/601 [06:37<26:45,  3.44s/round]",
            "\rRound:  22%|██▏       | 135/601 [06:40<25:02,  3.22s/round]",
            "\rRound:  23%|██▎       | 136/601 [06:43<25:23,  3.28s/round]",
            "\rRound:  23%|██▎       | 137/601 [06:47<25:26,  3.29s/round]",
            "\rRound:  23%|██▎       | 138/601 [06:53<32:33,  4.22s/round]",
            "\rRound:  23%|██▎       | 139/601 [06:57<30:56,  4.02s/round]",
            "\rRound:  23%|██▎       | 140/601 [07:00<29:25,  3.83s/round]",
            "\rRound:  23%|██▎       | 141/601 [07:03<27:42,  3.61s/round]",
            "\rRound:  24%|██▎       | 142/601 [07:06<26:31,  3.47s/round]",
            "\rRound:  24%|██▍       | 143/601 [07:08<23:37,  3.10s/round]",
            "\rRound:  24%|██▍       | 144/601 [07:11<23:20,  3.06s/round]",
            "\rRound:  24%|██▍       | 145/601 [07:16<26:45,  3.52s/round]",
            "\rRound:  24%|██▍       | 146/601 [07:22<31:24,  4.14s/round]",
            "\rRound:  24%|██▍       | 147/601 [07:28<37:13,  4.92s/round]",
            "\rRound:  25%|██▍       | 148/601 [07:33<36:35,  4.85s/round]",
            "\rRound:  25%|██▍       | 149/601 [07:42<44:48,  5.95s/round]",
            "\rRound:  25%|██▍       | 150/601 [07:46<41:05,  5.47s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 151\n(epoch = 1, round = 151, global round = 151), Loss/Training: 3044.5953419751395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 151, global round = 151), Accuracy/Training: 49.58559588453844\n(epoch = 1, round = 151, global round = 151), round_to_target/Training: 10000000000.0\nreporting (epoch = 1, round = 151, global round = 151) for aggregation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  25%|██▌       | 151/601 [07:51<40:24,  5.39s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 151, global round = 151), Loss/Aggregation: 2793.5030517578125\n(epoch = 1, round = 151, global round = 151), Accuracy/Aggregation: 59.09090909090909\n(epoch = 1, round = 151, global round = 151), round_to_target/Aggregation: 10000000000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  25%|██▌       | 152/601 [07:55<36:28,  4.87s/round]",
            "\rRound:  25%|██▌       | 153/601 [07:59<34:05,  4.57s/round]",
            "\rRound:  26%|██▌       | 154/601 [08:02<31:25,  4.22s/round]",
            "\rRound:  26%|██▌       | 155/601 [08:04<27:00,  3.63s/round]",
            "\rRound:  26%|██▌       | 156/601 [08:08<27:35,  3.72s/round]",
            "\rRound:  26%|██▌       | 157/601 [08:11<25:52,  3.50s/round]",
            "\rRound:  26%|██▋       | 158/601 [08:14<24:22,  3.30s/round]",
            "\rRound:  26%|██▋       | 159/601 [08:16<22:00,  2.99s/round]",
            "\rRound:  27%|██▋       | 160/601 [08:18<20:00,  2.72s/round]",
            "\rRound:  27%|██▋       | 161/601 [08:21<20:03,  2.73s/round]",
            "\rRound:  27%|██▋       | 162/601 [08:23<17:03,  2.33s/round]",
            "\rRound:  27%|██▋       | 163/601 [08:25<17:02,  2.33s/round]",
            "\rRound:  27%|██▋       | 164/601 [08:28<18:45,  2.57s/round]",
            "\rRound:  27%|██▋       | 165/601 [08:30<17:34,  2.42s/round]",
            "\rRound:  28%|██▊       | 166/601 [08:32<15:30,  2.14s/round]",
            "\rRound:  28%|██▊       | 167/601 [08:33<14:30,  2.01s/round]",
            "\rRound:  28%|██▊       | 168/601 [08:34<12:49,  1.78s/round]",
            "\rRound:  28%|██▊       | 169/601 [08:36<12:00,  1.67s/round]",
            "\rRound:  28%|██▊       | 170/601 [08:37<11:11,  1.56s/round]",
            "\rRound:  28%|██▊       | 171/601 [08:39<11:04,  1.55s/round]",
            "\rRound:  29%|██▊       | 172/601 [08:40<10:09,  1.42s/round]",
            "\rRound:  29%|██▉       | 173/601 [08:41<10:10,  1.43s/round]",
            "\rRound:  29%|██▉       | 174/601 [08:44<12:09,  1.71s/round]",
            "\rRound:  29%|██▉       | 175/601 [08:45<12:14,  1.72s/round]",
            "\rRound:  29%|██▉       | 176/601 [08:47<11:50,  1.67s/round]",
            "\rRound:  29%|██▉       | 177/601 [08:49<12:05,  1.71s/round]",
            "\rRound:  30%|██▉       | 178/601 [08:50<11:22,  1.61s/round]",
            "\rRound:  30%|██▉       | 179/601 [08:53<13:16,  1.89s/round]",
            "\rRound:  30%|██▉       | 180/601 [08:55<14:47,  2.11s/round]",
            "\rRound:  30%|███       | 181/601 [08:57<14:46,  2.11s/round]",
            "\rRound:  30%|███       | 182/601 [08:59<14:19,  2.05s/round]",
            "\rRound:  30%|███       | 183/601 [09:01<12:49,  1.84s/round]",
            "\rRound:  31%|███       | 184/601 [09:02<11:11,  1.61s/round]",
            "\rRound:  31%|███       | 185/601 [09:03<11:05,  1.60s/round]",
            "\rRound:  31%|███       | 186/601 [09:05<10:25,  1.51s/round]",
            "\rRound:  31%|███       | 187/601 [09:07<12:29,  1.81s/round]",
            "\rRound:  31%|███▏      | 188/601 [09:09<11:41,  1.70s/round]",
            "\rRound:  31%|███▏      | 189/601 [09:10<11:27,  1.67s/round]",
            "\rRound:  32%|███▏      | 190/601 [09:12<12:03,  1.76s/round]",
            "\rRound:  32%|███▏      | 191/601 [09:14<12:08,  1.78s/round]",
            "\rRound:  32%|███▏      | 192/601 [09:15<10:33,  1.55s/round]",
            "\rRound:  32%|███▏      | 193/601 [09:17<10:34,  1.56s/round]",
            "\rRound:  32%|███▏      | 194/601 [09:20<15:05,  2.23s/round]",
            "\rRound:  32%|███▏      | 195/601 [09:22<14:27,  2.14s/round]",
            "\rRound:  33%|███▎      | 196/601 [09:24<14:24,  2.14s/round]",
            "\rRound:  33%|███▎      | 197/601 [09:26<13:32,  2.01s/round]",
            "\rRound:  33%|███▎      | 198/601 [09:28<12:32,  1.87s/round]",
            "\rRound:  33%|███▎      | 199/601 [09:30<12:49,  1.91s/round]",
            "\rRound:  33%|███▎      | 200/601 [09:32<13:17,  1.99s/round]",
            "\rRound:  33%|███▎      | 201/601 [09:35<15:35,  2.34s/round]",
            "\rRound:  34%|███▎      | 202/601 [09:36<13:43,  2.06s/round]",
            "\rRound:  34%|███▍      | 203/601 [09:38<12:33,  1.89s/round]",
            "\rRound:  34%|███▍      | 204/601 [09:39<10:57,  1.66s/round]",
            "\rRound:  34%|███▍      | 205/601 [09:40<10:13,  1.55s/round]",
            "\rRound:  34%|███▍      | 206/601 [09:42<09:40,  1.47s/round]",
            "\rRound:  34%|███▍      | 207/601 [09:43<09:06,  1.39s/round]",
            "\rRound:  35%|███▍      | 208/601 [09:44<08:42,  1.33s/round]",
            "\rRound:  35%|███▍      | 209/601 [09:46<09:06,  1.39s/round]",
            "\rRound:  35%|███▍      | 210/601 [09:47<09:24,  1.44s/round]",
            "\rRound:  35%|███▌      | 211/601 [09:49<09:40,  1.49s/round]",
            "\rRound:  35%|███▌      | 212/601 [09:50<09:55,  1.53s/round]",
            "\rRound:  35%|███▌      | 213/601 [09:52<09:33,  1.48s/round]",
            "\rRound:  36%|███▌      | 214/601 [09:53<09:16,  1.44s/round]",
            "\rRound:  36%|███▌      | 215/601 [09:54<08:47,  1.37s/round]",
            "\rRound:  36%|███▌      | 216/601 [09:55<08:18,  1.29s/round]",
            "\rRound:  36%|███▌      | 217/601 [09:57<08:10,  1.28s/round]",
            "\rRound:  36%|███▋      | 218/601 [09:58<08:34,  1.34s/round]",
            "\rRound:  36%|███▋      | 219/601 [09:59<08:29,  1.33s/round]",
            "\rRound:  37%|███▋      | 220/601 [10:01<09:47,  1.54s/round]",
            "\rRound:  37%|███▋      | 221/601 [10:03<10:10,  1.61s/round]",
            "\rRound:  37%|███▋      | 222/601 [10:05<09:48,  1.55s/round]",
            "\rRound:  37%|███▋      | 223/601 [10:06<09:44,  1.55s/round]",
            "\rRound:  37%|███▋      | 224/601 [10:08<09:35,  1.53s/round]",
            "\rRound:  37%|███▋      | 225/601 [10:09<09:11,  1.47s/round]",
            "\rRound:  38%|███▊      | 226/601 [10:10<08:59,  1.44s/round]",
            "\rRound:  38%|███▊      | 227/601 [10:11<08:18,  1.33s/round]",
            "\rRound:  38%|███▊      | 228/601 [10:13<08:06,  1.31s/round]",
            "\rRound:  38%|███▊      | 229/601 [10:14<08:32,  1.38s/round]",
            "\rRound:  38%|███▊      | 230/601 [10:17<10:22,  1.68s/round]",
            "\rRound:  38%|███▊      | 231/601 [10:19<10:53,  1.76s/round]",
            "\rRound:  39%|███▊      | 232/601 [10:20<09:29,  1.54s/round]",
            "\rRound:  39%|███▉      | 233/601 [10:21<08:36,  1.40s/round]",
            "\rRound:  39%|███▉      | 234/601 [10:22<08:37,  1.41s/round]",
            "\rRound:  39%|███▉      | 235/601 [10:24<09:03,  1.49s/round]",
            "\rRound:  39%|███▉      | 236/601 [10:25<08:45,  1.44s/round]",
            "\rRound:  39%|███▉      | 237/601 [10:27<09:41,  1.60s/round]",
            "\rRound:  40%|███▉      | 238/601 [10:28<09:09,  1.52s/round]",
            "\rRound:  40%|███▉      | 239/601 [10:30<09:35,  1.59s/round]",
            "\rRound:  40%|███▉      | 240/601 [10:31<08:54,  1.48s/round]",
            "\rRound:  40%|████      | 241/601 [10:33<08:54,  1.49s/round]",
            "\rRound:  40%|████      | 242/601 [10:35<09:18,  1.56s/round]",
            "\rRound:  40%|████      | 243/601 [10:36<09:24,  1.58s/round]",
            "\rRound:  41%|████      | 244/601 [10:38<09:14,  1.55s/round]",
            "\rRound:  41%|████      | 245/601 [10:40<10:31,  1.77s/round]",
            "\rRound:  41%|████      | 246/601 [10:42<10:22,  1.75s/round]",
            "\rRound:  41%|████      | 247/601 [10:43<10:13,  1.73s/round]",
            "\rRound:  41%|████▏     | 248/601 [10:45<09:36,  1.63s/round]",
            "\rRound:  41%|████▏     | 249/601 [10:46<08:50,  1.51s/round]",
            "\rRound:  42%|████▏     | 250/601 [10:47<08:32,  1.46s/round]",
            "\rRound:  42%|████▏     | 251/601 [10:49<08:33,  1.47s/round]",
            "\rRound:  42%|████▏     | 252/601 [10:50<08:44,  1.50s/round]",
            "\rRound:  42%|████▏     | 253/601 [10:52<08:25,  1.45s/round]",
            "\rRound:  42%|████▏     | 254/601 [10:53<07:48,  1.35s/round]",
            "\rRound:  42%|████▏     | 255/601 [10:54<08:03,  1.40s/round]",
            "\rRound:  43%|████▎     | 256/601 [10:56<08:05,  1.41s/round]",
            "\rRound:  43%|████▎     | 257/601 [10:57<08:06,  1.41s/round]",
            "\rRound:  43%|████▎     | 258/601 [10:59<08:03,  1.41s/round]",
            "\rRound:  43%|████▎     | 259/601 [11:01<08:54,  1.56s/round]",
            "\rRound:  43%|████▎     | 260/601 [11:02<08:26,  1.49s/round]",
            "\rRound:  43%|████▎     | 261/601 [11:03<08:16,  1.46s/round]",
            "\rRound:  44%|████▎     | 262/601 [11:04<07:46,  1.38s/round]",
            "\rRound:  44%|████▍     | 263/601 [11:06<07:51,  1.40s/round]",
            "\rRound:  44%|████▍     | 264/601 [11:08<09:28,  1.69s/round]",
            "\rRound:  44%|████▍     | 265/601 [11:10<09:59,  1.79s/round]",
            "\rRound:  44%|████▍     | 266/601 [11:14<13:35,  2.43s/round]",
            "\rRound:  44%|████▍     | 267/601 [11:15<11:19,  2.03s/round]",
            "\rRound:  45%|████▍     | 268/601 [11:17<11:20,  2.04s/round]",
            "\rRound:  45%|████▍     | 269/601 [11:19<10:14,  1.85s/round]",
            "\rRound:  45%|████▍     | 270/601 [11:20<09:17,  1.69s/round]",
            "\rRound:  45%|████▌     | 271/601 [11:21<08:47,  1.60s/round]",
            "\rRound:  45%|████▌     | 272/601 [11:23<08:05,  1.47s/round]",
            "\rRound:  45%|████▌     | 273/601 [11:24<07:44,  1.42s/round]",
            "\rRound:  46%|████▌     | 274/601 [11:25<07:48,  1.43s/round]",
            "\rRound:  46%|████▌     | 275/601 [11:27<07:39,  1.41s/round]",
            "\rRound:  46%|████▌     | 276/601 [11:28<07:30,  1.38s/round]",
            "\rRound:  46%|████▌     | 277/601 [11:29<07:06,  1.32s/round]",
            "\rRound:  46%|████▋     | 278/601 [11:31<07:11,  1.34s/round]",
            "\rRound:  46%|████▋     | 279/601 [11:32<07:12,  1.34s/round]",
            "\rRound:  47%|████▋     | 280/601 [11:33<07:08,  1.33s/round]",
            "\rRound:  47%|████▋     | 281/601 [11:35<07:00,  1.31s/round]",
            "\rRound:  47%|████▋     | 282/601 [11:36<06:40,  1.26s/round]",
            "\rRound:  47%|████▋     | 283/601 [11:38<07:49,  1.48s/round]",
            "\rRound:  47%|████▋     | 284/601 [11:39<08:07,  1.54s/round]",
            "\rRound:  47%|████▋     | 285/601 [11:41<08:20,  1.58s/round]",
            "\rRound:  48%|████▊     | 286/601 [11:42<08:04,  1.54s/round]",
            "\rRound:  48%|████▊     | 287/601 [11:44<07:49,  1.49s/round]",
            "\rRound:  48%|████▊     | 288/601 [11:46<08:23,  1.61s/round]",
            "\rRound:  48%|████▊     | 289/601 [11:47<07:42,  1.48s/round]",
            "\rRound:  48%|████▊     | 290/601 [11:48<07:12,  1.39s/round]",
            "\rRound:  48%|████▊     | 291/601 [11:49<06:46,  1.31s/round]",
            "\rRound:  49%|████▊     | 292/601 [11:50<06:37,  1.29s/round]",
            "\rRound:  49%|████▉     | 293/601 [11:53<09:20,  1.82s/round]",
            "\rRound:  49%|████▉     | 294/601 [11:55<08:49,  1.73s/round]",
            "\rRound:  49%|████▉     | 295/601 [11:56<08:02,  1.58s/round]",
            "\rRound:  49%|████▉     | 296/601 [11:59<09:28,  1.86s/round]",
            "\rRound:  49%|████▉     | 297/601 [12:00<09:02,  1.79s/round]",
            "\rRound:  50%|████▉     | 298/601 [12:02<08:19,  1.65s/round]",
            "\rRound:  50%|████▉     | 299/601 [12:03<07:26,  1.48s/round]",
            "\rRound:  50%|████▉     | 300/601 [12:04<07:18,  1.46s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 301\n(epoch = 1, round = 301, global round = 301), Loss/Training: 9877.748178570651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 301, global round = 301), Accuracy/Training: 48.00323799244468\n(epoch = 1, round = 301, global round = 301), round_to_target/Training: 10000000000.0\nreporting (epoch = 1, round = 301, global round = 301) for aggregation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  50%|█████     | 301/601 [12:06<08:21,  1.67s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 301, global round = 301), Loss/Aggregation: 18748.871875\n(epoch = 1, round = 301, global round = 301), Accuracy/Aggregation: 14.285714285714286\n(epoch = 1, round = 301, global round = 301), round_to_target/Aggregation: 10000000000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  50%|█████     | 302/601 [12:08<07:38,  1.53s/round]",
            "\rRound:  50%|█████     | 303/601 [12:09<07:08,  1.44s/round]",
            "\rRound:  51%|█████     | 304/601 [12:10<06:57,  1.41s/round]",
            "\rRound:  51%|█████     | 305/601 [12:11<06:42,  1.36s/round]",
            "\rRound:  51%|█████     | 306/601 [12:13<06:23,  1.30s/round]",
            "\rRound:  51%|█████     | 307/601 [12:14<06:16,  1.28s/round]",
            "\rRound:  51%|█████     | 308/601 [12:15<06:27,  1.32s/round]",
            "\rRound:  51%|█████▏    | 309/601 [12:17<07:31,  1.55s/round]",
            "\rRound:  52%|█████▏    | 310/601 [12:19<07:13,  1.49s/round]",
            "\rRound:  52%|█████▏    | 311/601 [12:20<06:31,  1.35s/round]",
            "\rRound:  52%|█████▏    | 312/601 [12:21<06:04,  1.26s/round]",
            "\rRound:  52%|█████▏    | 313/601 [12:22<05:53,  1.23s/round]",
            "\rRound:  52%|█████▏    | 314/601 [12:23<05:49,  1.22s/round]",
            "\rRound:  52%|█████▏    | 315/601 [12:24<05:47,  1.22s/round]",
            "\rRound:  53%|█████▎    | 316/601 [12:26<05:52,  1.24s/round]",
            "\rRound:  53%|█████▎    | 317/601 [12:27<05:39,  1.20s/round]",
            "\rRound:  53%|█████▎    | 318/601 [12:29<06:37,  1.41s/round]",
            "\rRound:  53%|█████▎    | 319/601 [12:30<06:48,  1.45s/round]",
            "\rRound:  53%|█████▎    | 320/601 [12:33<08:24,  1.80s/round]",
            "\rRound:  53%|█████▎    | 321/601 [12:35<08:40,  1.86s/round]",
            "\rRound:  54%|█████▎    | 322/601 [12:36<08:26,  1.81s/round]",
            "\rRound:  54%|█████▎    | 323/601 [12:38<08:16,  1.79s/round]",
            "\rRound:  54%|█████▍    | 324/601 [12:39<07:18,  1.58s/round]",
            "\rRound:  54%|█████▍    | 325/601 [12:41<07:04,  1.54s/round]",
            "\rRound:  54%|█████▍    | 326/601 [12:42<07:16,  1.59s/round]",
            "\rRound:  54%|█████▍    | 327/601 [12:44<07:41,  1.68s/round]",
            "\rRound:  55%|█████▍    | 328/601 [12:45<07:02,  1.55s/round]",
            "\rRound:  55%|█████▍    | 329/601 [12:47<07:14,  1.60s/round]",
            "\rRound:  55%|█████▍    | 330/601 [12:49<07:12,  1.60s/round]",
            "\rRound:  55%|█████▌    | 331/601 [12:50<06:56,  1.54s/round]",
            "\rRound:  55%|█████▌    | 332/601 [12:52<07:01,  1.57s/round]",
            "\rRound:  55%|█████▌    | 333/601 [12:54<07:11,  1.61s/round]",
            "\rRound:  56%|█████▌    | 334/601 [12:55<06:56,  1.56s/round]",
            "\rRound:  56%|█████▌    | 335/601 [12:56<06:16,  1.42s/round]",
            "\rRound:  56%|█████▌    | 336/601 [12:57<05:53,  1.34s/round]",
            "\rRound:  56%|█████▌    | 337/601 [12:59<05:56,  1.35s/round]",
            "\rRound:  56%|█████▌    | 338/601 [13:00<05:35,  1.27s/round]",
            "\rRound:  56%|█████▋    | 339/601 [13:01<05:41,  1.30s/round]",
            "\rRound:  57%|█████▋    | 340/601 [13:02<05:26,  1.25s/round]",
            "\rRound:  57%|█████▋    | 341/601 [13:03<05:02,  1.16s/round]",
            "\rRound:  57%|█████▋    | 342/601 [13:04<05:03,  1.17s/round]",
            "\rRound:  57%|█████▋    | 343/601 [13:06<05:11,  1.21s/round]",
            "\rRound:  57%|█████▋    | 344/601 [13:07<05:07,  1.20s/round]",
            "\rRound:  57%|█████▋    | 345/601 [13:08<05:05,  1.19s/round]",
            "\rRound:  58%|█████▊    | 346/601 [13:09<04:52,  1.15s/round]",
            "\rRound:  58%|█████▊    | 347/601 [13:10<04:47,  1.13s/round]",
            "\rRound:  58%|█████▊    | 348/601 [13:11<04:41,  1.11s/round]",
            "\rRound:  58%|█████▊    | 349/601 [13:12<04:36,  1.10s/round]",
            "\rRound:  58%|█████▊    | 350/601 [13:14<05:05,  1.22s/round]",
            "\rRound:  58%|█████▊    | 351/601 [13:15<04:57,  1.19s/round]",
            "\rRound:  59%|█████▊    | 352/601 [13:16<05:00,  1.21s/round]",
            "\rRound:  59%|█████▊    | 353/601 [13:17<04:51,  1.17s/round]",
            "\rRound:  59%|█████▉    | 354/601 [13:19<05:04,  1.23s/round]",
            "\rRound:  59%|█████▉    | 355/601 [13:20<04:54,  1.20s/round]",
            "\rRound:  59%|█████▉    | 356/601 [13:21<04:48,  1.18s/round]",
            "\rRound:  59%|█████▉    | 357/601 [13:23<05:45,  1.42s/round]",
            "\rRound:  60%|█████▉    | 358/601 [13:24<05:39,  1.40s/round]",
            "\rRound:  60%|█████▉    | 359/601 [13:25<05:27,  1.35s/round]",
            "\rRound:  60%|█████▉    | 360/601 [13:28<06:30,  1.62s/round]",
            "\rRound:  60%|██████    | 361/601 [13:30<07:29,  1.87s/round]",
            "\rRound:  60%|██████    | 362/601 [13:32<07:05,  1.78s/round]",
            "\rRound:  60%|██████    | 363/601 [13:33<06:28,  1.63s/round]",
            "\rRound:  61%|██████    | 364/601 [13:34<06:01,  1.52s/round]",
            "\rRound:  61%|██████    | 365/601 [13:35<05:33,  1.41s/round]",
            "\rRound:  61%|██████    | 366/601 [13:37<05:28,  1.40s/round]",
            "\rRound:  61%|██████    | 367/601 [13:38<05:28,  1.41s/round]",
            "\rRound:  61%|██████    | 368/601 [13:39<05:20,  1.37s/round]",
            "\rRound:  61%|██████▏   | 369/601 [13:41<04:54,  1.27s/round]",
            "\rRound:  62%|██████▏   | 370/601 [13:42<05:12,  1.35s/round]",
            "\rRound:  62%|██████▏   | 371/601 [13:43<05:00,  1.31s/round]",
            "\rRound:  62%|██████▏   | 372/601 [13:44<04:49,  1.26s/round]",
            "\rRound:  62%|██████▏   | 373/601 [13:46<05:10,  1.36s/round]",
            "\rRound:  62%|██████▏   | 374/601 [13:47<04:47,  1.27s/round]",
            "\rRound:  62%|██████▏   | 375/601 [13:48<04:41,  1.25s/round]",
            "\rRound:  63%|██████▎   | 376/601 [13:49<04:35,  1.22s/round]",
            "\rRound:  63%|██████▎   | 377/601 [13:50<04:20,  1.16s/round]",
            "\rRound:  63%|██████▎   | 378/601 [13:52<04:11,  1.13s/round]",
            "\rRound:  63%|██████▎   | 379/601 [13:53<04:33,  1.23s/round]",
            "\rRound:  63%|██████▎   | 380/601 [13:54<04:36,  1.25s/round]",
            "\rRound:  63%|██████▎   | 381/601 [13:56<05:28,  1.49s/round]",
            "\rRound:  64%|██████▎   | 382/601 [13:58<05:05,  1.40s/round]",
            "\rRound:  64%|██████▎   | 383/601 [13:59<04:49,  1.33s/round]",
            "\rRound:  64%|██████▍   | 384/601 [14:00<04:29,  1.24s/round]",
            "\rRound:  64%|██████▍   | 385/601 [14:01<04:35,  1.28s/round]",
            "\rRound:  64%|██████▍   | 386/601 [14:02<04:21,  1.22s/round]",
            "\rRound:  64%|██████▍   | 387/601 [14:03<04:28,  1.26s/round]",
            "\rRound:  65%|██████▍   | 388/601 [14:05<04:49,  1.36s/round]",
            "\rRound:  65%|██████▍   | 389/601 [14:07<05:17,  1.50s/round]",
            "\rRound:  65%|██████▍   | 390/601 [14:09<05:50,  1.66s/round]",
            "\rRound:  65%|██████▌   | 391/601 [14:10<05:10,  1.48s/round]",
            "\rRound:  65%|██████▌   | 392/601 [14:11<04:45,  1.37s/round]",
            "\rRound:  65%|██████▌   | 393/601 [14:12<04:25,  1.28s/round]",
            "\rRound:  66%|██████▌   | 394/601 [14:14<04:31,  1.31s/round]",
            "\rRound:  66%|██████▌   | 395/601 [14:15<04:37,  1.35s/round]",
            "\rRound:  66%|██████▌   | 396/601 [14:16<04:15,  1.25s/round]",
            "\rRound:  66%|██████▌   | 397/601 [14:17<04:03,  1.19s/round]",
            "\rRound:  66%|██████▌   | 398/601 [14:18<03:54,  1.16s/round]",
            "\rRound:  66%|██████▋   | 399/601 [14:19<04:04,  1.21s/round]",
            "\rRound:  67%|██████▋   | 400/601 [14:21<04:03,  1.21s/round]",
            "\rRound:  67%|██████▋   | 401/601 [14:22<03:57,  1.19s/round]",
            "\rRound:  67%|██████▋   | 402/601 [14:24<05:03,  1.53s/round]",
            "\rRound:  67%|██████▋   | 403/601 [14:26<04:52,  1.48s/round]",
            "\rRound:  67%|██████▋   | 404/601 [14:27<04:40,  1.43s/round]",
            "\rRound:  67%|██████▋   | 405/601 [14:28<04:43,  1.44s/round]",
            "\rRound:  68%|██████▊   | 406/601 [14:29<04:19,  1.33s/round]",
            "\rRound:  68%|██████▊   | 407/601 [14:30<04:05,  1.27s/round]",
            "\rRound:  68%|██████▊   | 408/601 [14:32<04:01,  1.25s/round]",
            "\rRound:  68%|██████▊   | 409/601 [14:33<03:51,  1.21s/round]",
            "\rRound:  68%|██████▊   | 410/601 [14:34<03:49,  1.20s/round]",
            "\rRound:  68%|██████▊   | 411/601 [14:35<03:43,  1.18s/round]",
            "\rRound:  69%|██████▊   | 412/601 [14:37<04:03,  1.29s/round]",
            "\rRound:  69%|██████▊   | 413/601 [14:38<04:05,  1.31s/round]",
            "\rRound:  69%|██████▉   | 414/601 [14:39<03:56,  1.26s/round]",
            "\rRound:  69%|██████▉   | 415/601 [14:40<03:42,  1.20s/round]",
            "\rRound:  69%|██████▉   | 416/601 [14:42<03:47,  1.23s/round]",
            "\rRound:  69%|██████▉   | 417/601 [14:43<04:07,  1.35s/round]",
            "\rRound:  70%|██████▉   | 418/601 [14:46<05:04,  1.67s/round]",
            "\rRound:  70%|██████▉   | 419/601 [14:47<04:49,  1.59s/round]",
            "\rRound:  70%|██████▉   | 420/601 [14:48<04:41,  1.56s/round]",
            "\rRound:  70%|███████   | 421/601 [14:50<04:35,  1.53s/round]",
            "\rRound:  70%|███████   | 422/601 [14:51<04:28,  1.50s/round]",
            "\rRound:  70%|███████   | 423/601 [14:52<04:07,  1.39s/round]",
            "\rRound:  71%|███████   | 424/601 [14:54<03:59,  1.35s/round]",
            "\rRound:  71%|███████   | 425/601 [14:55<04:00,  1.37s/round]",
            "\rRound:  71%|███████   | 426/601 [14:56<03:54,  1.34s/round]",
            "\rRound:  71%|███████   | 427/601 [14:58<04:07,  1.42s/round]",
            "\rRound:  71%|███████   | 428/601 [14:59<03:43,  1.29s/round]",
            "\rRound:  71%|███████▏  | 429/601 [15:00<03:38,  1.27s/round]",
            "\rRound:  72%|███████▏  | 430/601 [15:01<03:24,  1.19s/round]",
            "\rRound:  72%|███████▏  | 431/601 [15:02<03:13,  1.14s/round]",
            "\rRound:  72%|███████▏  | 432/601 [15:03<03:07,  1.11s/round]",
            "\rRound:  72%|███████▏  | 433/601 [15:05<03:23,  1.21s/round]",
            "\rRound:  72%|███████▏  | 434/601 [15:06<03:46,  1.35s/round]",
            "\rRound:  72%|███████▏  | 435/601 [15:08<04:01,  1.45s/round]",
            "\rRound:  73%|███████▎  | 436/601 [15:09<03:48,  1.38s/round]",
            "\rRound:  73%|███████▎  | 437/601 [15:11<03:40,  1.34s/round]",
            "\rRound:  73%|███████▎  | 438/601 [15:12<03:45,  1.38s/round]",
            "\rRound:  73%|███████▎  | 439/601 [15:13<03:39,  1.36s/round]",
            "\rRound:  73%|███████▎  | 440/601 [15:14<03:20,  1.25s/round]",
            "\rRound:  73%|███████▎  | 441/601 [15:15<03:09,  1.18s/round]",
            "\rRound:  74%|███████▎  | 442/601 [15:16<03:00,  1.14s/round]",
            "\rRound:  74%|███████▎  | 443/601 [15:18<02:56,  1.12s/round]",
            "\rRound:  74%|███████▍  | 444/601 [15:19<02:57,  1.13s/round]",
            "\rRound:  74%|███████▍  | 445/601 [15:20<02:52,  1.11s/round]",
            "\rRound:  74%|███████▍  | 446/601 [15:22<03:29,  1.35s/round]",
            "\rRound:  74%|███████▍  | 447/601 [15:23<03:16,  1.28s/round]",
            "\rRound:  75%|███████▍  | 448/601 [15:25<03:50,  1.50s/round]",
            "\rRound:  75%|███████▍  | 449/601 [15:26<03:39,  1.44s/round]",
            "\rRound:  75%|███████▍  | 450/601 [15:28<03:43,  1.48s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 451\n(epoch = 1, round = 451, global round = 451), Loss/Training: 12214.730515387819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 451, global round = 451), Accuracy/Training: 48.82693900082804\n(epoch = 1, round = 451, global round = 451), round_to_target/Training: 10000000000.0\nreporting (epoch = 1, round = 451, global round = 451) for aggregation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  75%|███████▌  | 451/601 [15:30<03:59,  1.59s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 451, global round = 451), Loss/Aggregation: 30933.81259765625\n(epoch = 1, round = 451, global round = 451), Accuracy/Aggregation: 63.63636363636363\n(epoch = 1, round = 451, global round = 451), round_to_target/Aggregation: 10000000000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound:  75%|███████▌  | 452/601 [15:31<03:38,  1.47s/round]",
            "\rRound:  75%|███████▌  | 453/601 [15:32<03:21,  1.36s/round]",
            "\rRound:  76%|███████▌  | 454/601 [15:33<03:02,  1.24s/round]",
            "\rRound:  76%|███████▌  | 455/601 [15:34<02:54,  1.20s/round]",
            "\rRound:  76%|███████▌  | 456/601 [15:35<02:47,  1.16s/round]",
            "\rRound:  76%|███████▌  | 457/601 [15:36<02:58,  1.24s/round]",
            "\rRound:  76%|███████▌  | 458/601 [15:38<03:12,  1.35s/round]",
            "\rRound:  76%|███████▋  | 459/601 [15:40<03:26,  1.45s/round]",
            "\rRound:  77%|███████▋  | 460/601 [15:41<03:34,  1.52s/round]",
            "\rRound:  77%|███████▋  | 461/601 [15:43<03:24,  1.46s/round]",
            "\rRound:  77%|███████▋  | 462/601 [15:44<03:23,  1.46s/round]",
            "\rRound:  77%|███████▋  | 463/601 [15:45<03:03,  1.33s/round]",
            "\rRound:  77%|███████▋  | 464/601 [15:47<03:07,  1.37s/round]",
            "\rRound:  77%|███████▋  | 465/601 [15:48<03:18,  1.46s/round]",
            "\rRound:  78%|███████▊  | 466/601 [15:50<03:16,  1.46s/round]",
            "\rRound:  78%|███████▊  | 467/601 [15:51<02:58,  1.33s/round]",
            "\rRound:  78%|███████▊  | 468/601 [15:52<02:48,  1.27s/round]",
            "\rRound:  78%|███████▊  | 469/601 [15:53<02:58,  1.35s/round]",
            "\rRound:  78%|███████▊  | 470/601 [15:55<02:51,  1.31s/round]",
            "\rRound:  78%|███████▊  | 471/601 [15:56<02:44,  1.27s/round]",
            "\rRound:  79%|███████▊  | 472/601 [15:57<02:35,  1.21s/round]",
            "\rRound:  79%|███████▊  | 473/601 [15:58<02:31,  1.18s/round]",
            "\rRound:  79%|███████▉  | 474/601 [15:59<02:37,  1.24s/round]",
            "\rRound:  79%|███████▉  | 475/601 [16:01<02:34,  1.23s/round]",
            "\rRound:  79%|███████▉  | 476/601 [16:02<02:31,  1.21s/round]",
            "\rRound:  79%|███████▉  | 477/601 [16:03<02:27,  1.19s/round]",
            "\rRound:  80%|███████▉  | 478/601 [16:04<02:27,  1.20s/round]",
            "\rRound:  80%|███████▉  | 479/601 [16:05<02:23,  1.17s/round]",
            "\rRound:  80%|███████▉  | 480/601 [16:07<02:35,  1.28s/round]",
            "\rRound:  80%|████████  | 481/601 [16:08<02:28,  1.24s/round]",
            "\rRound:  80%|████████  | 482/601 [16:09<02:21,  1.19s/round]",
            "\rRound:  80%|████████  | 483/601 [16:10<02:29,  1.27s/round]",
            "\rRound:  81%|████████  | 484/601 [16:11<02:22,  1.21s/round]",
            "\rRound:  81%|████████  | 485/601 [16:13<02:37,  1.36s/round]",
            "\rRound:  81%|████████  | 486/601 [16:16<03:12,  1.67s/round]",
            "\rRound:  81%|████████  | 487/601 [16:17<03:08,  1.66s/round]",
            "\rRound:  81%|████████  | 488/601 [16:19<03:10,  1.69s/round]",
            "\rRound:  81%|████████▏ | 489/601 [16:20<02:54,  1.56s/round]",
            "\rRound:  82%|████████▏ | 490/601 [16:21<02:32,  1.38s/round]",
            "\rRound:  82%|████████▏ | 491/601 [16:22<02:17,  1.25s/round]",
            "\rRound:  82%|████████▏ | 492/601 [16:23<02:10,  1.20s/round]",
            "\rRound:  82%|████████▏ | 493/601 [16:25<02:16,  1.26s/round]",
            "\rRound:  82%|████████▏ | 494/601 [16:26<02:26,  1.37s/round]",
            "\rRound:  82%|████████▏ | 495/601 [16:28<02:30,  1.42s/round]",
            "\rRound:  83%|████████▎ | 496/601 [16:29<02:27,  1.41s/round]",
            "\rRound:  83%|████████▎ | 497/601 [16:30<02:13,  1.28s/round]",
            "\rRound:  83%|████████▎ | 498/601 [16:31<02:11,  1.28s/round]",
            "\rRound:  83%|████████▎ | 499/601 [16:33<02:09,  1.27s/round]",
            "\rRound:  83%|████████▎ | 500/601 [16:34<02:08,  1.27s/round]",
            "\rRound:  83%|████████▎ | 501/601 [16:35<02:09,  1.29s/round]",
            "\rRound:  84%|████████▎ | 502/601 [16:37<02:33,  1.56s/round]",
            "\rRound:  84%|████████▎ | 503/601 [16:39<02:41,  1.65s/round]",
            "\rRound:  84%|████████▍ | 504/601 [16:41<02:33,  1.58s/round]",
            "\rRound:  84%|████████▍ | 505/601 [16:43<02:38,  1.65s/round]",
            "\rRound:  84%|████████▍ | 506/601 [16:45<02:50,  1.79s/round]",
            "\rRound:  84%|████████▍ | 507/601 [16:46<02:38,  1.69s/round]",
            "\rRound:  85%|████████▍ | 508/601 [16:47<02:20,  1.51s/round]",
            "\rRound:  85%|████████▍ | 509/601 [16:49<02:19,  1.52s/round]",
            "\rRound:  85%|████████▍ | 510/601 [16:50<02:17,  1.52s/round]",
            "\rRound:  85%|████████▌ | 511/601 [16:51<02:05,  1.40s/round]",
            "\rRound:  85%|████████▌ | 512/601 [16:52<01:53,  1.28s/round]",
            "\rRound:  85%|████████▌ | 513/601 [16:53<01:47,  1.22s/round]",
            "\rRound:  86%|████████▌ | 514/601 [16:55<01:45,  1.22s/round]",
            "\rRound:  86%|████████▌ | 515/601 [16:56<01:50,  1.28s/round]",
            "\rRound:  86%|████████▌ | 516/601 [16:57<01:44,  1.23s/round]",
            "\rRound:  86%|████████▌ | 517/601 [16:58<01:38,  1.17s/round]",
            "\rRound:  86%|████████▌ | 518/601 [16:59<01:33,  1.13s/round]",
            "\rRound:  86%|████████▋ | 519/601 [17:00<01:33,  1.15s/round]",
            "\rRound:  87%|████████▋ | 520/601 [17:02<01:30,  1.11s/round]",
            "\rRound:  87%|████████▋ | 521/601 [17:03<01:28,  1.10s/round]",
            "\rRound:  87%|████████▋ | 522/601 [17:04<01:27,  1.11s/round]",
            "\rRound:  87%|████████▋ | 523/601 [17:05<01:25,  1.10s/round]",
            "\rRound:  87%|████████▋ | 524/601 [17:06<01:24,  1.10s/round]",
            "\rRound:  87%|████████▋ | 525/601 [17:07<01:20,  1.05s/round]",
            "\rRound:  88%|████████▊ | 526/601 [17:08<01:21,  1.08s/round]",
            "\rRound:  88%|████████▊ | 527/601 [17:09<01:21,  1.11s/round]",
            "\rRound:  88%|████████▊ | 528/601 [17:10<01:17,  1.06s/round]",
            "\rRound:  88%|████████▊ | 529/601 [17:11<01:12,  1.01s/round]",
            "\rRound:  88%|████████▊ | 530/601 [17:12<01:11,  1.00s/round]",
            "\rRound:  88%|████████▊ | 531/601 [17:14<01:27,  1.25s/round]",
            "\rRound:  89%|████████▊ | 532/601 [17:15<01:29,  1.29s/round]",
            "\rRound:  89%|████████▊ | 533/601 [17:16<01:22,  1.21s/round]",
            "\rRound:  89%|████████▉ | 534/601 [17:18<01:27,  1.30s/round]",
            "\rRound:  89%|████████▉ | 535/601 [17:19<01:28,  1.34s/round]",
            "\rRound:  89%|████████▉ | 536/601 [17:21<01:28,  1.36s/round]",
            "\rRound:  89%|████████▉ | 537/601 [17:22<01:22,  1.29s/round]",
            "\rRound:  90%|████████▉ | 538/601 [17:23<01:27,  1.39s/round]",
            "\rRound:  90%|████████▉ | 539/601 [17:24<01:19,  1.28s/round]",
            "\rRound:  90%|████████▉ | 540/601 [17:25<01:14,  1.22s/round]",
            "\rRound:  90%|█████████ | 541/601 [17:28<01:34,  1.57s/round]",
            "\rRound:  90%|█████████ | 542/601 [17:29<01:33,  1.58s/round]",
            "\rRound:  90%|█████████ | 543/601 [17:30<01:21,  1.41s/round]",
            "\rRound:  91%|█████████ | 544/601 [17:32<01:20,  1.42s/round]",
            "\rRound:  91%|█████████ | 545/601 [17:34<01:26,  1.55s/round]",
            "\rRound:  91%|█████████ | 546/601 [17:35<01:21,  1.49s/round]",
            "\rRound:  91%|█████████ | 547/601 [17:37<01:20,  1.50s/round]",
            "\rRound:  91%|█████████ | 548/601 [17:39<01:29,  1.68s/round]",
            "\rRound:  91%|█████████▏| 549/601 [17:40<01:25,  1.65s/round]",
            "\rRound:  92%|█████████▏| 550/601 [17:42<01:23,  1.64s/round]",
            "\rRound:  92%|█████████▏| 551/601 [17:43<01:17,  1.55s/round]",
            "\rRound:  92%|█████████▏| 552/601 [17:45<01:12,  1.48s/round]",
            "\rRound:  92%|█████████▏| 553/601 [17:46<01:06,  1.39s/round]",
            "\rRound:  92%|█████████▏| 554/601 [17:47<01:04,  1.37s/round]",
            "\rRound:  92%|█████████▏| 555/601 [17:48<01:02,  1.35s/round]",
            "\rRound:  93%|█████████▎| 556/601 [17:49<00:58,  1.29s/round]",
            "\rRound:  93%|█████████▎| 557/601 [17:50<00:52,  1.20s/round]",
            "\rRound:  93%|█████████▎| 558/601 [17:52<00:57,  1.33s/round]",
            "\rRound:  93%|█████████▎| 559/601 [17:54<00:59,  1.42s/round]",
            "\rRound:  93%|█████████▎| 560/601 [17:56<01:12,  1.77s/round]",
            "\rRound:  93%|█████████▎| 561/601 [17:58<01:03,  1.60s/round]",
            "\rRound:  94%|█████████▎| 562/601 [17:59<00:59,  1.53s/round]",
            "\rRound:  94%|█████████▎| 563/601 [18:00<00:56,  1.48s/round]",
            "\rRound:  94%|█████████▍| 564/601 [18:01<00:49,  1.33s/round]",
            "\rRound:  94%|█████████▍| 565/601 [18:02<00:45,  1.25s/round]",
            "\rRound:  94%|█████████▍| 566/601 [18:03<00:41,  1.17s/round]",
            "\rRound:  94%|█████████▍| 567/601 [18:04<00:39,  1.15s/round]",
            "\rRound:  95%|█████████▍| 568/601 [18:05<00:37,  1.13s/round]",
            "\rRound:  95%|█████████▍| 569/601 [18:07<00:37,  1.16s/round]",
            "\rRound:  95%|█████████▍| 570/601 [18:08<00:35,  1.13s/round]",
            "\rRound:  95%|█████████▌| 571/601 [18:09<00:32,  1.09s/round]",
            "\rRound:  95%|█████████▌| 572/601 [18:10<00:31,  1.09s/round]",
            "\rRound:  95%|█████████▌| 573/601 [18:12<00:38,  1.36s/round]",
            "\rRound:  96%|█████████▌| 574/601 [18:13<00:36,  1.37s/round]",
            "\rRound:  96%|█████████▌| 575/601 [18:14<00:32,  1.26s/round]",
            "\rRound:  96%|█████████▌| 576/601 [18:15<00:29,  1.18s/round]",
            "\rRound:  96%|█████████▌| 577/601 [18:16<00:26,  1.09s/round]",
            "\rRound:  96%|█████████▌| 578/601 [18:18<00:27,  1.18s/round]",
            "\rRound:  96%|█████████▋| 579/601 [18:19<00:27,  1.24s/round]",
            "\rRound:  97%|█████████▋| 580/601 [18:20<00:25,  1.20s/round]",
            "\rRound:  97%|█████████▋| 581/601 [18:22<00:28,  1.42s/round]",
            "\rRound:  97%|█████████▋| 582/601 [18:23<00:26,  1.37s/round]",
            "\rRound:  97%|█████████▋| 583/601 [18:24<00:23,  1.31s/round]",
            "\rRound:  97%|█████████▋| 584/601 [18:26<00:21,  1.27s/round]",
            "\rRound:  97%|█████████▋| 585/601 [18:27<00:19,  1.21s/round]",
            "\rRound:  98%|█████████▊| 586/601 [18:28<00:18,  1.25s/round]",
            "\rRound:  98%|█████████▊| 587/601 [18:29<00:16,  1.18s/round]",
            "\rRound:  98%|█████████▊| 588/601 [18:30<00:15,  1.20s/round]",
            "\rRound:  98%|█████████▊| 589/601 [18:31<00:14,  1.19s/round]",
            "\rRound:  98%|█████████▊| 590/601 [18:33<00:13,  1.27s/round]",
            "\rRound:  98%|█████████▊| 591/601 [18:34<00:12,  1.20s/round]",
            "\rRound:  99%|█████████▊| 592/601 [18:35<00:11,  1.27s/round]",
            "\rRound:  99%|█████████▊| 593/601 [18:37<00:10,  1.33s/round]",
            "\rRound:  99%|█████████▉| 594/601 [18:38<00:09,  1.31s/round]",
            "\rRound:  99%|█████████▉| 595/601 [18:39<00:07,  1.33s/round]",
            "\rRound:  99%|█████████▉| 596/601 [18:40<00:06,  1.26s/round]",
            "\rRound:  99%|█████████▉| 597/601 [18:42<00:05,  1.26s/round]",
            "\rRound: 100%|█████████▉| 598/601 [18:43<00:03,  1.25s/round]",
            "\rRound: 100%|█████████▉| 599/601 [18:44<00:02,  1.18s/round]",
            "\rRound: 100%|█████████▉| 600/601 [18:45<00:01,  1.17s/round]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train finished Global Round: 601\n(epoch = 1, round = 601, global round = 601), Loss/Training: 23256.68788273116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 601, global round = 601), Accuracy/Training: 54.00398974066686\n(epoch = 1, round = 601, global round = 601), round_to_target/Training: 10000000000.0\nreporting (epoch = 1, round = 601, global round = 601) for aggregation\n(epoch = 1, round = 601, global round = 601), Loss/Aggregation: 21179.43720703125\n(epoch = 1, round = 601, global round = 601), Accuracy/Aggregation: 70.58823529411765\n(epoch = 1, round = 601, global round = 601), round_to_target/Aggregation: 10000000000.0\nRunning (epoch = 1, round = 601, global round = 601) for Eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 601, global round = 601), Loss/Eval: 24499.7828654215\n(epoch = 1, round = 601, global round = 601), Accuracy/Eval: 55.10344827586207\n(epoch = 1, round = 601, global round = 601), round_to_target/Eval: 10000000000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRound: 100%|█████████▉| 600/601 [18:58<00:01,  1.90s/round]",
            "\n\rEpoch:   0%|          | 0/1 [18:58<?, ?epoch/s]",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "945fc6b7-a479-4fa1-a75c-3cf241a3f245",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": true
      },
      "source": [
        "After training finishes, we evaluate the model and report the test set accuracy before concluding this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "87a50242-9574-41b3-bf39-6f296f44005e",
        "showInput": true,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fb7b0794-1455-4805-9e97-c8649d0cb213",
        "executionStartTime": 1636677467822,
        "executionStopTime": 1636677479301
      },
      "source": [
        "# We can now test our model.\n",
        "trainer.test(\n",
        "    data_iter=data_provider.test_data(),\n",
        "    metric_reporter=MetricsReporter([Channel.STDOUT]),\n",
        ")\n",
        ""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running (epoch = 1, round = 1, global round = 1) for Test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(epoch = 1, round = 1, global round = 1), Loss/Test: 24499.782963370133\n(epoch = 1, round = 1, global round = 1), Accuracy/Test: 55.10344827586207\n(epoch = 1, round = 1, global round = 1), round_to_target/Test: 10000000000.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'Accuracy': 55.10344827586207, 'round_to_target': 10000000000.0}"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "835d5964-8dbf-458a-8360-b8cd30f7a4c4",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we first showed how to get and preprocess LEAF's Sent140 dataset. \n",
        "We then built a data provider by splitting each user's data into batches. \n",
        "We defined a simple char-LSTM as our model, wrapped it with a model compatible with FL training, and moved it to GPU. \n",
        "Lastly, we set the hyperparameters for FL training, launched the training flow, and evaluated our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "663d0a7d-dd3c-401f-8f8e-b1db9ffd3cce",
        "showInput": false,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Additional resources\n",
        "- [FLSim tutorials](https://github.com/facebookresearch/FLSim/tree/main/tutorials) - check out our other tutorial on sentiment classification.\n",
        "- Kairouz et al. (2021): [Advances and Open Problems in Federated Learning](https://arxiv.org/pdf/1912.04977.pdf). As the title suggests, an in-depth overview of advances and open problems in FL.\n",
        "- If you're interested in federated learning with **differential privacy**, take a look at [Opacus](https://opacus.ai/), a library that enables training PyTorch models with differential privacy. \n",
        "You can find a blog post introducing Opacus [here](https://ai.facebook.com/blog/introducing-opacus-a-high-speed-library-for-training-pytorch-models-with-differential-privacy/).\n",
        "\n",
        ""
      ]
    }
  ]
}
