{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "08ca4e30-5070-4da4-a0b7-1cf5f7436381",
    "last_kernel_id": "63245ad5-44e4-4720-aaa8-d0392223a644",
    "last_base_url": "https://3080.od.fbinfra.net:443/",
    "last_msg_id": "10fc83ca-6bf68c4248a127403f129c52_4103",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "originalKey": "69ac5df6-d268-4402-857c-52a28e1b82a7",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "# FLSim Tutorial: Adding a custom communication channel"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "18383e0f-4c17-47c7-9b6a-0e55ea272b84",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Introduction\n",
        "\n",
        "In this tutorial, you will learn to implement your custom channel to allow the server and the clients to communicate with each other. A custom channel might be needed to simulate various real-life scenarios, for instance when compressing the model updates computed on the client side before sending them to the server, where the updates will be decompressed and then aggregated."
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "2b9a4c4a-183d-47ad-a424-dbe64fe5fffe",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Prerequisites\n",
        "\n",
        "To get the most of this tutorial, you should be comfortable training machine learning models with FLSim. Moreover, if you are not familiar with standard compression techniques, please take a look at the following resources:\n",
        "- [PyTorch intro to Scalar Quantization](https://pytorch.org/docs/stable/quantization.html) (in particular `int8`).\n",
        "- Some papers related to the quantization setup in the context of Federated learning (FL) or Distributed Server-Side Training: [Quantized-SGD](https://arxiv.org/abs/1610.02132), [Atomo](https://proceedings.neurips.cc/paper/2018/file/33b3214d792caf311e1f00fd22b392c5-Paper.pdf), [Power-SGD\n",
        "](https://proceedings.neurips.cc/paper/2019/file/d9fbed9da256e344c1fa46bb46c34c5f-Paper.pdf)\n",
        "\n",
        "Now that you're familiar with FLSim and compression, let's move on!"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "d129e43b-2a97-4e60-bdfc-dc931014b79a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn:\n",
        "- The structure of a [`Message`](https://github.com/facebookresearch/FLSim/blob/main/channels/message.py#L15) used to communicate any relevant information between the server and the clients. \n",
        "- The API of a channel with the example of the [`IdentityChannel`](https://github.com/facebookresearch/FLSim/blob/main/channels/base_channel.py#L59). It implements a pass-through without any modification to the underlying message.\n",
        "- How to implement a custom channel with the example of the [`ScalarQuantizationChannel`](https://github.com/facebookresearch/FLSim/blob/main/channels/scalar_quantization_channel.py#L23).\n",
        "- How to perform a training in FLSim with your custom channel.\n",
        "- How to measure the number of bytes sent from the client to the server and from the server to the client."
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "a8ea7bf2-b454-43a2-868e-d5536343c75e",
        "showInput": false,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a8ea7bf2-b454-43a2-868e-d5536343c75e",
        "executionStartTime": 1638285870329,
        "executionStopTime": 1638285870344,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "# 1 - The `Message` dataclass\n",
        "\n",
        "First, before diving in to the channel component, what's a [`Message`](https://github.com/facebookresearch/FLSim/blob/main/channels/message.py#L15)?"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3b14361e-b33e-44fa-b960-0794d724a3ec",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b928a78f-8623-4e0f-894d-59393887c169",
        "executionStartTime": 1638462871873,
        "executionStopTime": 1638462871907
      },
      "source": [
        "from flsim.channels.message import Message\n",
        "from flsim.tests import utils\n",
        "\n",
        "\n",
        "net = utils.SampleNet(utils.TwoFC())\n",
        "message = Message(net)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "9e1e1a8d-0808-448c-b17a-c3f7547dc5c8",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9e1e1a8d-0808-448c-b17a-c3f7547dc5c8",
        "executionStartTime": 1638286506954,
        "executionStopTime": 1638286507253
      },
      "source": [
        "Simply put, a message contains:\n",
        "- The model (`nn.Module`) that is being trained.\n",
        "- Any meta information such as the weight used when aggregating updates from multiple clients.\n",
        "\n",
        "Sometimes (see below for scalar quantization), it's easier for the channel to work on the `state_dict()` of the model. Hence, we allow ourselves to populate the message with the state dict of the model used to instantiate it. Vice-versa, we allow to update the model attribute of the message after manipulating and changing its state dict. It is the responsibility of the user to make sure that, then the state dict is populated, it coincides with the state dict of the model."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cb0b595e-d564-4e57-8040-91c251ab4653",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "96fc74d9-988f-499b-a346-163328a7db61",
        "executionStartTime": 1638462872107,
        "executionStopTime": 1638462872225
      },
      "source": [
        "print(\"Before populating\", message.model_state_dict)\n",
        "message.populate_state_dict()\n",
        "print(\"After populating\", message.model_state_dict)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before populating OrderedDict()\nAfter populating OrderedDict([('fc1.weight', tensor([[ 0.5033,  0.6609],\n        [ 0.3683, -0.1048],\n        [ 0.4713,  0.4913],\n        [-0.0736,  0.3803],\n        [-0.1871,  0.0246]])), ('fc1.bias', tensor([-0.5928, -0.0246, -0.0602,  0.5279, -0.0213])), ('fc2.weight', tensor([[ 0.2424, -0.0060, -0.3095,  0.4453,  0.2060]])), ('fc2.bias', tensor([0.1402]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "71680e07-7a66-4bf7-b1e5-f3463980926d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c6d3b195-83b6-4adc-9853-4fb7327fd1e8",
        "executionStartTime": 1638462872305,
        "executionStopTime": 1638462872346
      },
      "source": [
        "message.model_state_dict[\"fc1.weight\"].fill_(0)\n",
        "print(\"Before updating model with state dict\", message.model.sample_nn.fc1.weight)\n",
        "message.update_model_()\n",
        "print(\"After updating model\", message.model.sample_nn.fc1.weight)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before updating model with state dict Parameter containing:\ntensor([[ 0.5033,  0.6609],\n        [ 0.3683, -0.1048],\n        [ 0.4713,  0.4913],\n        [-0.0736,  0.3803],\n        [-0.1871,  0.0246]], requires_grad=True)\nAfter updating model Parameter containing:\ntensor([[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "db0e8861-9fae-4d95-8e81-b5118778aa1e",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "db0e8861-9fae-4d95-8e81-b5118778aa1e",
        "executionStartTime": 1638286972782,
        "executionStopTime": 1638286973093
      },
      "source": [
        "# 2 - The Identity Channel\n",
        "\n",
        "Open the file [`channels/base_channel.py`](https://github.com/facebookresearch/FLSim/blob/main/channels/base_channel.py). The public API of `IdentityChannel` is made of two main functions:\n",
        "- [`client_to_server`](https://github.com/facebookresearch/FLSim/blob/main/channels/base_channel.py#L162) that performs three successive steps to send a message from a client to the server.\n",
        "- [`server_to_client`](https://github.com/facebookresearch/FLSim/blob/main/channels/base_channel.py#L173) that performs three successive steps to send a message from the server to a client.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "88a5ca96-f2da-4fee-9db1-1efe08f62363",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9d165b6d-5a23-4a21-aee5-595e2dfcd7ac",
        "executionStartTime": 1638462872359,
        "executionStopTime": 1638462872433
      },
      "source": [
        "from flsim.channels.base_channel import FLChannelConfig\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "\n",
        "config = FLChannelConfig()\n",
        "identity_channel = instantiate(config)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "f3e8fef1-6973-4a7d-b3f8-e050a7724bbd",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f3e8fef1-6973-4a7d-b3f8-e050a7724bbd",
        "executionStartTime": 1638287198599,
        "executionStopTime": 1638287198817
      },
      "source": [
        "Let's verify that the channel implements a pass-through, *i.e.* that the channel does not modify the message it transmits."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d0df15bd-48ca-4b40-aff7-2036511faffa",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "247b226e-a52a-4096-9dcf-8051daf8f0ad",
        "executionStartTime": 1638462872587,
        "executionStopTime": 1638462872595,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "net = utils.SampleNet(utils.TwoFC())\n",
        "message_before = Message(net)\n",
        "\n",
        "message_after = identity_channel.client_to_server(message_before)\n",
        "assert message_after == message_before \n",
        "\n",
        "message_after = identity_channel.server_to_client(message_before)\n",
        "assert message_after == message_before "
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "ba2ed6d4-26ae-4bec-bedb-fe30ebb39916",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ba2ed6d4-26ae-4bec-bedb-fe30ebb39916",
        "executionStartTime": 1638287256763,
        "executionStopTime": 1638287256770
      },
      "source": [
        "# 3 - Implement your own channel"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "28b4cd75-2f66-4fe8-a1aa-dab91e84a0de",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Now, let's dive deeper into the channel API. You may have noticed that the following things happen under the hood when calling the [`client_to_server`](https://github.com/facebookresearch/FLSim/blob/main/channels/base_channel.py#L162) method in the `IdentityChannel`: \n",
        "\n",
        "```python\n",
        "message = self._on_client_before_transmission(message)\n",
        "message = self._during_transmission_client_to_server(message)\n",
        "message = self._on_server_after_reception(message)\n",
        "```\n",
        "\n",
        "Since any channel inherits `IdentityChannel`, *we only need to override the parts that change*. For instance, since we wish to implement the identity in the server->client direction, we do not override the corresponding three functions inside the `server_to_client` method.\n",
        "\n",
        "\n",
        "Let's break these three steps down using the concrete example of the [`ScalarQuantization`](https://github.com/facebookresearch/FLSim/blob/main/channels/scalar_quantization_channel.py#L23) channel. The goal of this channel is to compress the model state dict *only* in the client->server direction and to implement the identity in the server->client direction."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "68a3e2ca-e559-43e3-a3e1-fb5f97e4f02b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "16592c33-b301-4a7b-bae6-3cf112e9983d",
        "executionStartTime": 1638462873092,
        "executionStopTime": 1638462873203
      },
      "source": [
        "from flsim.channels.scalar_quantization_channel import ScalarQuantizationChannelConfig\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "\n",
        "config = ScalarQuantizationChannelConfig(n_bits=8, report_communication_metrics=True)\n",
        "sq_channel = instantiate(config)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "48595e50-356e-4775-9fc1-2d339f5f20e6",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "First, let's print the originak network weights"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "efb06dd6-1d39-4915-a32d-41e849b11f9e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8696d98e-d2c0-4a46-aead-d8bfec14a068",
        "executionStartTime": 1638462962761,
        "executionStopTime": 1638462962771
      },
      "source": [
        "net = utils.SampleNet(utils.TwoFC())\n",
        "message = Message(net)\n",
        "\n",
        "print(message.model.fl_get_module().state_dict()[\"fc1.weight\"])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0155,  0.6545],\n        [-0.4280, -0.3730],\n        [ 0.0649, -0.0991],\n        [ 0.1245, -0.5659],\n        [ 0.3703,  0.4525]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "48614efa-33e1-4986-a690-c02d069b8a57",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "48614efa-33e1-4986-a690-c02d069b8a57",
        "executionStartTime": 1638287813834,
        "executionStopTime": 1638287813942
      },
      "source": [
        "**on_client_before_transmission**: here we need to\n",
        "1. Populate the state dict of the message (see part 1 of this tutorial)\n",
        "2. Quantize all parameters (except for the biases due to their small overhead)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "dc796417-8269-41db-8a1d-bd3cb6b4b56d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fbb3bf83-69a7-4321-adea-4f42ce104736",
        "executionStartTime": 1638462970200,
        "executionStopTime": 1638462970209
      },
      "source": [
        "# we quantize over 8 bits here, and return a PyTorch quantized tensor\n",
        "# note that the weights have lost some resolution, which is expected\n",
        "message = sq_channel._on_client_before_transmission(message)\n",
        "print(message.model_state_dict[\"fc1.weight\"])"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0144,  0.6557],\n        [-0.4260, -0.3733],\n        [ 0.0670, -0.1005],\n        [ 0.1244, -0.5648],\n        [ 0.3685,  0.4547]], size=(5, 2), dtype=torch.quint8,\n       quantization_scheme=torch.per_tensor_affine, scale=0.004786025732755661,\n       zero_point=118)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "f4ea3d1d-6b00-47f7-9497-01a28dd0e1a9",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f4ea3d1d-6b00-47f7-9497-01a28dd0e1a9",
        "executionStartTime": 1638287874270,
        "executionStopTime": 1638287874588
      },
      "source": [
        "**during_transmission_client_to_server**: here we can optionally measure the (compressed) message size, more on this in part 4 of this tutorial."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e4f96294-a830-468a-b4e7-e98e719a9e9f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "e4f96294-a830-468a-b4e7-e98e719a9e9f",
        "executionStartTime": 1638299621522,
        "executionStopTime": 1638299621529
      },
      "source": [
        "from flsim.channels.communication_stats import ChannelDirection\n",
        "\n",
        "\n",
        "message = sq_channel._during_transmission_client_to_server(message)\n",
        "\n",
        "\n",
        "direction = ChannelDirection.CLIENT_TO_SERVER\n",
        "stats = sq_channel.stats_collector.get_channel_stats()[direction]\n",
        "print(f\"Number of bytes sent from client to server: {stats.mean()}\")"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bytes sent from client to server: 63.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5ec8f6a9-82fa-46bb-a4fb-7bcb2829ee51",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5ec8f6a9-82fa-46bb-a4fb-7bcb2829ee51",
        "executionStartTime": 1638293435528,
        "executionStopTime": 1638293435642
      },
      "source": [
        "**_on_server_after_reception**: here we need to: \n",
        "1. Update `message.model` to match the updated state dict (see part 1 of this tutorial).\n",
        "2. Dequantize all the parameters that were quantized. "
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ea56e082-4b58-429c-8c03-d02f86ab6e88",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ea56e082-4b58-429c-8c03-d02f86ab6e88",
        "executionStartTime": 1638297869072,
        "executionStopTime": 1638297869180
      },
      "source": [
        "# we are back to a PyTorch fp32 tensor\n",
        "message = sq_channel._on_server_after_reception(message)\n",
        "print(message.model_state_dict[\"fc1.weight\"])"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6959, -0.6632],\n        [-0.5491, -0.5926],\n        [ 0.6904, -0.1196],\n        [-0.2827,  0.2338],\n        [ 0.5926,  0.4675]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "22ad7cd6-9245-484a-8c24-7a84692e4f57",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "# 4 - Measure message size"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "513eedfd-ae94-4460-8943-e27576d8a863",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "The message size is gathered through a [`StatsCollector`](https://github.com/facebookresearch/FLSim/blob/main/channels/communication_stats.py#L14) for both directions (client to server and server to client). Let's quickly check that the server->client message is larger than the client_server message (since this one is compressed).\n",
        "\n",
        "Note that here the compresion raio is not 4x since we also need to transmit the per-tensor scales and zero points (and the weight matrices we are considering are rather small: for larger networks, we would be clost to 4x)."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8d5a8c17-de58-4104-ac45-d55b8635ac2e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8d5a8c17-de58-4104-ac45-d55b8635ac2e",
        "executionStartTime": 1638299619422,
        "executionStopTime": 1638299619429
      },
      "source": [
        "from flsim.channels.communication_stats import ChannelDirection\n",
        "\n",
        "\n",
        "# we need to forward the message at least once to measure its size\n",
        "message = sq_channel.server_to_client(message)\n",
        "\n",
        "\n",
        "direction = ChannelDirection.SERVER_TO_CLIENT\n",
        "stats = sq_channel.stats_collector.get_channel_stats()[direction]\n",
        "print(f\"Number of bytes sent from server to client: {stats.mean()}\")"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bytes sent from server to client: 84.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "f4823038-3e00-4268-a14f-17b3d2cafe15",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f4823038-3e00-4268-a14f-17b3d2cafe15",
        "executionStartTime": 1638299751301,
        "executionStopTime": 1638299751667
      },
      "source": [
        "If you wish to go deeper, you need to override the [`_calc_message_size_client_to_server`](https://github.com/facebookresearch/FLSim/blob/main/channels/scalar_quantization_channel.py#L68) function to tailor the measurement of the message size for your custom channel. Please check [`ScalarQuantizationChannel`]([`_calc_message_size_client_to_server`](https://github.com/facebookresearch/FLSim/blob/main/channels/scalar_quantization_channel.py#L68) for an example!"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "5d4e50a4-bda4-4dff-bc11-d65b0ed5763a",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5d4e50a4-bda4-4dff-bc11-d65b0ed5763a",
        "executionStartTime": 1638287302846,
        "executionStopTime": 1638287302901
      },
      "source": [
        "# 5 - Training in FLSim with a custom channel"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "729f92a4-821c-495a-817a-dc5655043ab0",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Simply specify the config of your channel in the training file, see example below. Then, refer to the training tutorial in FLSim."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4d102933-325a-4a37-86a7-9ecdd176ec7f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4d102933-325a-4a37-86a7-9ecdd176ec7f",
        "executionStartTime": 1638297869206,
        "executionStopTime": 1638297869436
      },
      "source": [
        "json_config = {\n",
        "    \"trainer\": {\n",
        "        \"_base_\": \"base_sync_trainer\",\n",
        "        # there are different types of aggegator\n",
        "        # fed avg doesn't require lr, while others such as fed_sgd fed_adam do\n",
        "        \"aggregator\": {\"_base_\": \"base_fed_avg_sync_aggregator\"},\n",
        "        \"client\": {\n",
        "            # number of client's local epochs\n",
        "            \"epochs\": 1,\n",
        "            \"optimizer\": {\n",
        "                \"_base_\": \"base_optimizer_sgd\",\n",
        "                # client's local learning rate\n",
        "                \"lr\": 0.01,\n",
        "                # client's local momentum\n",
        "                \"momentum\": 0.9,\n",
        "            },\n",
        "        },\n",
        "        # insert here your favourite channel along with its config!\n",
        "        \"channel\": {\n",
        "            \"_base_\": \"base_scalar_quantization_channel\",\n",
        "            \"n_bits\": 8,\n",
        "            \"quantize_per_tensor\": True,\n",
        "        },\n",
        "        # type of user selection sampling\n",
        "        \"active_user_selector\": {\"_base_\": \"base_sequential_active_user_selector\"},\n",
        "        # number of users per round for aggregation\n",
        "        \"users_per_round\": 5,\n",
        "        # total number of global epochs\n",
        "        # total #rounds = ceil(total_users / users_per_round) * epochs\n",
        "        \"epochs\": 1,\n",
        "        # frequency of reporting train metrics\n",
        "        \"train_metrics_reported_per_epoch\": 10,\n",
        "        # frequency of evaluation per epoch\n",
        "        \"eval_epoch_frequency\": 1,\n",
        "        \"do_eval\": True,\n",
        "        # should we report train metrics after global aggregation\n",
        "        \"report_train_metrics_after_aggregation\": True,\n",
        "    }\n",
        "}"
      ],
      "execution_count": 196,
      "outputs": []
    }
  ]
}
